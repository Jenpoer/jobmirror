{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffce314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import dateparser\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b16a7",
   "metadata": {},
   "source": [
    "# SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9707e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/cnamuangtoun/resume-job-description-fit/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf38c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc7cc9",
   "metadata": {},
   "source": [
    "# BRONZE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba7fce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edbf69",
   "metadata": {},
   "source": [
    "## Resume Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d154b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "    \n",
    "class Experience(BaseModel):\n",
    "    role: Optional[str] = Field(None, description=\"The job title or position held\")\n",
    "    company: Optional[str] = Field(None, description=\"The name of the company\")\n",
    "    date_start: Optional[datetime.datetime] = Field(None, description=\"The start date of the job\")\n",
    "    date_end: Optional[datetime.datetime] = Field(None, description=\"The end date of the job\")\n",
    "    role_description: Optional[str] = Field(None, description=\"A description of the responsibilities and achievements in the role\")\n",
    "\n",
    "class Education(BaseModel):\n",
    "    degree: Optional[str] = Field(None, description=\"The academic degree obtained\")\n",
    "    institution: Optional[str] = Field(None, description=\"The name of the educational institution\")\n",
    "    date_start: Optional[datetime.datetime] = Field(None, description=\"The start date of the education program\")\n",
    "    date_end: Optional[datetime.datetime] = Field(None, description=\"The end date of the education program\")\n",
    "    grade: Optional[float] = Field(None, description=\"The GPA or final grade, if available\")\n",
    "    description: Optional[str] = Field(None, description=\"Additional details about the education\")\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    name: Optional[str] = Field(None, description=\"Full name of the person\")\n",
    "    location_preference: Optional[str] = Field(None, description=\"Preference for their work location / remote, if stated\")\n",
    "    work_authorizaton: Optional[str] = Field(None, description=\"Work authorization that the person holds, such as citizenship, if stated\")\n",
    "    employment_type_preference: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Type of employment the resume is looking for such as Full-time, Part-time, Contract, Freelance, or Internship, if stated\"\n",
    "    )\n",
    "    hard_skills: List[str] = Field(..., description=\"A list of hard or technical skills mentioned in the resume\")\n",
    "    soft_skills: List[str] = Field(..., description=\"A list of soft skills mentioned in the resume, such as communication, teamwork, and leadership\")\n",
    "    languages: List[str]= Field(..., description=\"A list of language proficiencies mentioned in the resume\")\n",
    "    experience: List[Experience] = Field(..., description=\"A list of past work experiences\")\n",
    "    education: List[Education] = Field(..., description=\"A list of educational qualifications\")\n",
    "\n",
    "# Create the parser\n",
    "resume_parser = PydanticOutputParser(pydantic_object=Resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7bc4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "resume_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that extracts structured information from resumes.\"),\n",
    "    (\"human\", \"Extract the following information from the resume:\\n\\n{text}\\n\\n{format_instructions}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7233d",
   "metadata": {},
   "source": [
    "## Job Desc Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f413bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models for job desc\n",
    "\n",
    "class JD(BaseModel):\n",
    "    company_name: Optional[str] = Field(None, description=\"Name of the company posting the job\")\n",
    "    role_title: Optional[str] = Field(None, description=\"The title or name of the job role being offered\")\n",
    "    employment_type: Optional[str] = Field(None, description=\"Type of employment, such as Full-time, Part-time, Contract, Freelance, or Internship\")\n",
    "    about_the_company: Optional[str] = Field(None, description=\"A brief overview or description of the company\")\n",
    "    job_responsibilities: List[str] = Field(..., description=\"A list of key duties, tasks, or responsibilities associated with the job\")\n",
    "    required_hard_skills: List[str] = Field(..., description=\"A list of technical or hard skills required or preferred for the job\")\n",
    "    required_soft_skills: List[str] = Field(..., description=\"A list of soft skills or character required or preferred for the job\")\n",
    "    required_language_proficiencies: List[str] = Field(..., description=\"A list of language proficiencies required for the job\")\n",
    "    required_work_authorization: Optional[str] = Field(None, description=\"Work authorization required for the job\")\n",
    "    job_location: Optional[str] = Field(None, description=\"Location where the job is based, such as a city or remote\")\n",
    "\n",
    "# Create the parser\n",
    "jd_parser = PydanticOutputParser(pydantic_object=JD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba4865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "jd_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that extracts structured information from job descriptions.\"),\n",
    "    (\"human\", \"Extract the following information from the job description:\\n\\n{text}\\n\\n{format_instructions}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2cac6",
   "metadata": {},
   "source": [
    "## Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e289d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to parse text with llm\n",
    "def parse_with_llm(text, prompt_template, parser, llm):\n",
    "    prompt = prompt_template.format_messages(\n",
    "        text=text,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb440d",
   "metadata": {},
   "source": [
    "### Parse resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9e7d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = parse_with_llm(df['resume_text'].iloc[6236], resume_prompt_template, resume_parser, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d61c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": null,\n",
      "  \"location_preference\": null,\n",
      "  \"work_authorizaton\": null,\n",
      "  \"employment_type_preference\": null,\n",
      "  \"hard_skills\": [\n",
      "    \"Data Management\",\n",
      "    \"Database Management\",\n",
      "    \"Data Compilation\",\n",
      "    \"Attention to Detail\",\n",
      "    \"Data Review\",\n",
      "    \"Microsoft Office Suite\",\n",
      "    \"Document Management and Storage\",\n",
      "    \"Multitasking and Prioritization\",\n",
      "    \"Time Management\",\n",
      "    \"Data Verification\",\n",
      "    \"Administrative Support\",\n",
      "    \"Microsoft Access\",\n",
      "    \"Microsoft Excel\",\n",
      "    \"Adobe Software\"\n",
      "  ],\n",
      "  \"soft_skills\": [\n",
      "    \"Decision Making\",\n",
      "    \"Service-Oriented\",\n",
      "    \"Self-Starter\",\n",
      "    \"Workflow Management\",\n",
      "    \"Team player\"\n",
      "  ],\n",
      "  \"languages\": [],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"role\": \"Data Entry Specialist\",\n",
      "      \"company\": \"Sonic Healthcare Usa\",\n",
      "      \"date_start\": \"2020-09-01T00:00:00\",\n",
      "      \"date_end\": \"2023-11-21T15:16:19\",\n",
      "      \"role_description\": \"Input client information into spreadsheets and company database to provide leaders with quick access to essential client data.\\nIdentified, corrected and reported data entry errors.\\nCompleted accurate and efficient data entry and database updates to support business operations.\\nIdentified and corrected data entry errors to prevent duplication across systems.\\nCompiled data from source documents prior to data entry.\\nReviewed and updated account information in company computer system.\\nIdentified errors in data entry and related issues by mentioning to supervisors for resolution.\\nSorted source documents and organized to be filed.\\nAdhered to sClairect data confidentiality policies to prevent information leakage.\\nCommunicated with coworkers regarding deadlines and project milestones.\\nProofread and edited documents to correct errors.\\nDocumented data entry completions in corresponding logbooks.\\nExecuted data verification to ensure expedient error detection.\\nExceeded quality goals to support team productivity.\\nMonitored updates to company databases and corrected identified errors.\\nTransferred completed work to Title Officers for review and approval.\\nReviewed source documents to locate required data for entry.\\nProduced new orders in Streamline Management Services and Greenfolders to manage samples and associated data.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Manager\",\n",
      "      \"company\": \"Community Health System\",\n",
      "      \"date_start\": \"2018-11-01T00:00:00\",\n",
      "      \"date_end\": \"2020-09-01T00:00:00\",\n",
      "      \"role_description\": \"Trained employees on additional job positions to maintain coverage of roles.\\nAssigned tasks to associates to fit skill levels and maximize team performance.\\nGreeted and encouraged feedback from customers to implement in-store operational changesCompleted thorough opening, closing and shift change functions to maintain operational standards each day.\\nEnforced customer service standards and resolved customer problems to uphold quality service.\\nExercised good judgment and decision-making in escalating concerns and resolving issues.\\nOversaw daily workloads and workflow for smooth operations.\\nManaged shifts in absence of store manager to deliver excellent customer service while promoting sales.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Crew Member\",\n",
      "      \"company\": \"Marcus Corporation\",\n",
      "      \"date_start\": \"2016-06-01T00:00:00\",\n",
      "      \"date_end\": \"2018-08-01T00:00:00\",\n",
      "      \"role_description\": \"Wiped down tables and equipment, swept and refilled stock.\\nKept restaurant lobby, front counter and restrooms neat and clean throughout shift.\\nPacked fast food products in approved containers, cups and bags.\\nEntered orders into computer system to send order details to kitchen, mentioning customers' special requests and food allergies in person.\\nPrepared quality products while maintaining portion control and presentation within service goal times.\\nDrove team success by quickly completing assigned tasks.\\nDemonstrated proper food safety practices by accurately completing quality control checklist.\\nOrganized and restocked supplies to support operations and team productivity.\\nServed food quickly for positive guest experiences.\\nPackaged menu items into bags or trays and placed drink orders into carriers.\\nExplained current promotional information and items to patrons.\\nAssisted management with inventory control and stock ordering.\\nPresented orders to guests within anticipated service times.\\nRestocked supplies, removed trash and cleaned areas.\\nAnswered customer questions and took orders.\\nPrepared products by adding tags and readying pallets for restocking.\\nOperated fryers and grills, assisted with putting orders together and bagged items for customers.\\nTotaled bills, accepted payments and returned change.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Cashier\",\n",
      "      \"company\": \"Kohler\",\n",
      "      \"date_start\": \"2017-06-01T00:00:00\",\n",
      "      \"date_end\": \"2018-04-01T00:00:00\",\n",
      "      \"role_description\": \"Collected payments and provided accurate change.\\nCompleted daily recovery tasks to keep areas clean and neat for maximum productivity.\\nWorked closely with front-end staff to assist customers.\\nAccepted cash and credit card payments, issued receipts and provided change.\\nTrained new team members in cash register operation, stock procedures and customer services.\\nLearned roles of other departments to provide coverage and keep store operational.\\nOperated cash register or POS system to receive payment by cash, check and credit card.\\nReported pricing discrepancies to supervisor.\\nAnswered customer questions and provided store information.\\nDelivered high level of customer service to patrons using active listening and engagement skills.\\nPreserved appearance of store by arranging and replenishing displays and merchandise racks.\"\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"High School Diploma\",\n",
      "      \"institution\": \"Idea Homeschool\",\n",
      "      \"date_start\": null,\n",
      "      \"date_end\": null,\n",
      "      \"grade\": null,\n",
      "      \"description\": null\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143dea9a",
   "metadata": {},
   "source": [
    "### Parse job desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1b7e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "Hope you are doing great today. Please find the job description below. Let me know your job interest as soon as possible. I will highly appreciate it if you can refer somebody suitable for this position. \n",
      "Role: Data Engineer (Oracle and DataStage).Location: RemoteContract Position\n",
      "Job Description:RoleResponsibilities:Skills: Oracle, Datastage, UNIX, PLSQL, SQL. Good to have: AWS, Matillion, Snowflake. Data engineering experience; expert level experience with SQL. Experience with the cloud (AWS, Azure andor Google Cloud Platform).  Experience in cloud-based data warehouses (Snowflake, Google BigQuery, Amazon Redshift, Azure Synapse Analytics).  Experience with cloud-based ETLELT tools (Matillion, Glue, Data Factory) and data modelling.  Experience with version control systems (Git, SVN).  Understanding of and willingness to embrace Agile Principles. \n",
      "Looking forward to your response . \n",
      "Shubhanshu Tripathishubhanshu.t@cblsolutions.com 469-947-7816 (Ext  209)Cerebral Technologies, Inc (D.B.A CBLSolutions) http:cblsolutions.com400 E Royal Lane, Ste 235, Irving, TX - 75039 Linkedin: https:www.linkedin.cominshubhanshu-tripathi-058228213 \n"
     ]
    }
   ],
   "source": [
    "print(df['job_description_text'].iloc[6236])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57dd896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_jd = parse_with_llm(df['job_description_text'].iloc[6236], jd_prompt_template, jd_parser, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3fefe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"company_name\": \"Cerebral Technologies, Inc\",\n",
      "  \"role_title\": \"Data Engineer\",\n",
      "  \"employment_type\": \"Contract\",\n",
      "  \"about_the_company\": null,\n",
      "  \"job_responsibilities\": [],\n",
      "  \"required_hard_skills\": [\n",
      "    \"Oracle\",\n",
      "    \"Datastage\",\n",
      "    \"UNIX\",\n",
      "    \"PLSQL\",\n",
      "    \"SQL\",\n",
      "    \"AWS\",\n",
      "    \"Matillion\",\n",
      "    \"Snowflake\",\n",
      "    \"Data engineering\",\n",
      "    \"SQL\",\n",
      "    \"AWS\",\n",
      "    \"Azure\",\n",
      "    \"Google Cloud Platform\",\n",
      "    \"Snowflake\",\n",
      "    \"Google BigQuery\",\n",
      "    \"Amazon Redshift\",\n",
      "    \"Azure Synapse Analytics\",\n",
      "    \"Matillion\",\n",
      "    \"Glue\",\n",
      "    \"Data Factory\",\n",
      "    \"Git\",\n",
      "    \"SVN\"\n",
      "  ],\n",
      "  \"required_soft_skills\": [\n",
      "    \"Agile Principles\"\n",
      "  ],\n",
      "  \"required_language_proficiencies\": [],\n",
      "  \"required_work_authorization\": null,\n",
      "  \"job_location\": \"Remote\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_jd.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f185d77",
   "metadata": {},
   "source": [
    "# SILVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a8a66",
   "metadata": {},
   "source": [
    "# GOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5416e",
   "metadata": {},
   "source": [
    "## Get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "52d6567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1f948ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_required_skills = embedding_model.embed_documents(parsed_jd.required_skills)\n",
    "embeddings_skills_owned = embedding_model.embed_documents(parsed_data.skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "93af6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_skills = np.array(embeddings_required_skills)\n",
    "skills_owned = np.array(embeddings_skills_owned)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "required_skills = required_skills / np.linalg.norm(required_skills, axis=1, keepdims=True)\n",
    "skills_owned = skills_owned / np.linalg.norm(skills_owned, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(required_skills, skills_owned.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4ae5fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required: Oracle  <=> Best Owned: Database Management  | Similarity: 0.68\n",
      "Required: Datastage  <=> Best Owned: Data Management  | Similarity: 0.72\n",
      "Required: UNIX  <=> Best Owned: Database Management  | Similarity: 0.62\n",
      "Required: PLSQL  <=> Best Owned: Database Management  | Similarity: 0.70\n",
      "Required: SQL  <=> Best Owned: Database Management  | Similarity: 0.80\n",
      "Required: SQL  <=> Best Owned: Database Management  | Similarity: 0.80\n",
      "Required: Google Cloud Platform  <=> Best Owned: Data Management  | Similarity: 0.61\n",
      "Required: Google BigQuery  <=> Best Owned: Data Management  | Similarity: 0.64\n",
      "Required: Azure Synapse Analytics  <=> Best Owned: Data Management  | Similarity: 0.62\n",
      "Required: Data Factory  <=> Best Owned: Data Management  | Similarity: 0.75\n",
      "Required: Agile Principles  <=> Best Owned: Service-Oriented  | Similarity: 0.63\n"
     ]
    }
   ],
   "source": [
    "best_matches = []\n",
    "\n",
    "for i, req_skill in enumerate(parsed_jd.required_skills):\n",
    "    j = similarity_matrix[i].argmax()\n",
    "    score = similarity_matrix[i, j]\n",
    "    if score >= 0.6:\n",
    "        best_matches.append((req_skill, parsed_data.skills[j], score))\n",
    "\n",
    "# Print\n",
    "for req_skill, own_skill, score in best_matches:\n",
    "    print(f\"Required: {req_skill}  <=> Best Owned: {own_skill}  | Similarity: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "991dbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_role_name = embedding_model.embed_query(parsed_jd.role_title)\n",
    "embeddings_experience_titles = embedding_model.embed_documents([exp.role for exp in parsed_data.experience])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "65b9e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Engineer'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_jd.role_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b4e5d683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Entry Specialist', 'Manager', 'Crew Member', 'Cashier']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[exp.role for exp in parsed_data.experience]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "31d693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = np.array(embeddings_role_name)\n",
    "experiences = np.array(embeddings_experience_titles)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "role_name = role_name / np.linalg.norm(role_name)\n",
    "experiences = experiences / np.linalg.norm(experiences, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(experiences, role_name.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e5a979df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66697192, 0.54300044, 0.5427064 , 0.50708114])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
