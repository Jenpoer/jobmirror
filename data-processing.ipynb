{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ffce314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import dateparser\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, get_origin, get_args, Union\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, FloatType, BooleanType, TimestampType, StructField, StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b16a7",
   "metadata": {},
   "source": [
    "# SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191b92b",
   "metadata": {},
   "source": [
    "Import from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9707e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/cnamuangtoun/resume-job-description-fit/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14ada8",
   "metadata": {},
   "source": [
    "Generate random snapshot dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7a9971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seeded Generator\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# Define start and end date\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "end_date = pd.to_datetime('2025-01-01')\n",
    "\n",
    "# Generate random timestamps between start_date and end_date\n",
    "random_dates = pd.to_datetime(\n",
    "    rng.uniform(start_date.value, end_date.value, size=len(df))\n",
    ")\n",
    "\n",
    "# Ensure it's treated as a pandas Series and convert to date\n",
    "df['snapshot_date'] = pd.Series(random_dates).dt.date  # This will convert to date format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb271e43",
   "metadata": {},
   "source": [
    "Generate random IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13c86898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_id(prefix: str, length=8, use_digits=True, use_letters=True, seed=42):\n",
    "    rng = np.random.default_rng(seed=seed) \n",
    "\n",
    "    characters = ''\n",
    "    \n",
    "    if use_digits:\n",
    "        characters += string.digits\n",
    "    if use_letters:\n",
    "        characters += string.ascii_letters\n",
    "\n",
    "    # Ensure we have characters to choose from\n",
    "    if not characters:\n",
    "        raise ValueError(\"At least one of 'use_digits' or 'use_letters' must be True.\")\n",
    "    \n",
    "    # Use np.random.choice to randomly select characters\n",
    "    random_id = ''.join(rng.choice(list(characters), size=length))\n",
    "    return prefix + random_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resume_id'] = df.apply(lambda row: generate_random_id('RES_', seed=row.name), axis=1)\n",
    "df['job_id'] = df.apply(lambda row: generate_random_id('JD_', seed=row.name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4750cc",
   "metadata": {},
   "source": [
    "Setup env & pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf38c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3db7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_uri =  os.getenv(\"MONGODB_URI\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SaveJSONtoMongoDB\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", mongodb_uri) \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", mongodb_uri) \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.5.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc7cc9",
   "metadata": {},
   "source": [
    "# BRONZE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba7fce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edbf69",
   "metadata": {},
   "source": [
    "## Resume Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d154b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "    \n",
    "class Experience(BaseModel):\n",
    "    role: Optional[str] = Field(None, description=\"The job title or position held\")\n",
    "    company: Optional[str] = Field(None, description=\"The name of the company\")\n",
    "    date_start: Optional[datetime.datetime] = Field(None, description=\"The start date of the job\")\n",
    "    date_end: Optional[datetime.datetime] = Field(None, description=\"The end date of the job\")\n",
    "    role_description: Optional[str] = Field(None, description=\"A description of the responsibilities and achievements in the role\")\n",
    "\n",
    "class Education(BaseModel):\n",
    "    degree: Optional[str] = Field(None, description=\"The academic degree obtained\")\n",
    "    institution: Optional[str] = Field(None, description=\"The name of the educational institution\")\n",
    "    date_start: Optional[datetime.datetime] = Field(None, description=\"The start date of the education program\")\n",
    "    date_end: Optional[datetime.datetime] = Field(None, description=\"The end date of the education program\")\n",
    "    grade: Optional[float] = Field(None, description=\"The GPA or final grade, if available\")\n",
    "    description: Optional[str] = Field(None, description=\"Additional details about the education\")\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    name: Optional[str] = Field(None, description=\"Full name of the person\")\n",
    "    location_preference: Optional[str] = Field(None, description=\"Preference for their work location or remote, if stated\")\n",
    "    work_authorization: Optional[str] = Field(None, description=\"Work authorization that the person holds, such as citizenship, if stated\")\n",
    "    employment_type_preference: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Type of employment the resume is looking for such as Full-time, Part-time, Contract, Freelance, or Internship, if stated\"\n",
    "    )\n",
    "    hard_skills: List[str] = Field(..., \n",
    "                                   description=\"A list of proficiencies in tools, technologies, frameworks, programming languages, platforms, methodologies, and key professional terms mentioned in the resume. \" \\\n",
    "                                   \"Avoid duplicates and use concise wording.\" \\\n",
    "                                   \"Clean up tool names and merge variations.\")\n",
    "    soft_skills: List[str] = Field(..., description=\"A list of soft skills mentioned in the resume, such as communication, teamwork, and leadership. Avoid duplication.\")\n",
    "    languages: List[str]= Field(..., description=\"A list of language proficiencies mentioned in the resume\")\n",
    "    experience: List[Experience] = Field(..., description=\"A list of past work experiences\")\n",
    "    education: List[Education] = Field(..., description=\"A list of educational qualifications\")\n",
    "    certifications: List[str] = Field(..., description=\"A list of certifications or licenses mentioned in the resume, such as AWS Certified Solutions Architect, PMP, etc.\")\n",
    "\n",
    "# Create the parser\n",
    "resume_parser = PydanticOutputParser(pydantic_object=Resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7bc4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "resume_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that extracts structured information from resumes.\"),\n",
    "    (\"human\", \"Extract the following information from the resume:\\n\\n{text}\\n\\n{format_instructions}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7233d",
   "metadata": {},
   "source": [
    "## Job Desc Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f413bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models for job desc\n",
    "\n",
    "class JD(BaseModel):\n",
    "    company_name: Optional[str] = Field(None, description=\"Name of the company posting the job\")\n",
    "    role_title: Optional[str] = Field(None, description=\"The title or name of the job role being offered\")\n",
    "    employment_type: Optional[str] = Field(None, description=\"Type of employment, such as Full-time, Part-time, Contract, Freelance, or Internship\")\n",
    "    about_the_company: Optional[str] = Field(None, description=\"A brief overview or description of the company\")\n",
    "    job_responsibilities: List[str] = Field(..., description=\"A list of key duties, tasks, or responsibilities associated with the job\")\n",
    "    required_hard_skills: List[str] = Field(..., description=\"A list of technical or hard skills required or preferred for the job\")\n",
    "    required_soft_skills: List[str] = Field(..., description=\"A list of soft skills or character required or preferred for the job\")\n",
    "    required_language_proficiencies: List[str] = Field(..., description=\"A list of language proficiencies required for the job\")\n",
    "    required_work_authorization: Optional[str] = Field(None, description=\"Work authorization required for the job\")\n",
    "    required_education: Optional[str] = Field(None, description=\"The minimum educational qualification required for the job, such as a degree or certification\")\n",
    "    job_location: Optional[str] = Field(None, description=\"Location where the job is based, such as a city or remote\")\n",
    "\n",
    "# Create the parser\n",
    "jd_parser = PydanticOutputParser(pydantic_object=JD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aba4865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "jd_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that extracts structured information from job descriptions.\"),\n",
    "    (\"human\", \"Extract the following information from the job description:\\n\\n{text}\\n\\n{format_instructions}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2cac6",
   "metadata": {},
   "source": [
    "## Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e289d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to parse text with llm\n",
    "def parse_with_llm(text, prompt_template, parser, llm):\n",
    "    prompt = prompt_template.format_messages(\n",
    "        text=text,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb440d",
   "metadata": {},
   "source": [
    "### Parse resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef3eaf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SummaryFull stack Software Engineer with 8+ years of experience in software industry. Professional, creative, responsible with proven analytical skills and knowledge of Microsoft .Net platform and PHP. Passionate about new technologies and software development. Fast learner, focused, problem solver, great Team Player, and lover of good software development practices including Systems Development Life Cycle (SDLC).\n",
      "HighlightsC#, PHP.Technologies/Services: ASP.NET, ASP.NET MVC, ASP.NET Web API, EF, ADO.NET, T-SQL, .NET Framework, LINQ, Razor, Hangfire, SignalR, HTML, HTML5, XML, CSS, CSS3, JSON, AJAX, jQuery, AngularJS, Bootstrap, SOAP, REST, Alfresco ECM, Alfresco Activiti BPM, Alfresco OCR, OCR, Tesseract, AWS S3, AWS EC2, CodeIgniter, Composer, Google Maps API, Apache Web Server, Apache Tomcat, PL/pgSQL, LaTeX.Databases: MS SQL Server, PostgreSQL, MySQL.Source Code Control: SVN, GIT.Project Management Tool: Redmine, Gforge.IDEs: Visual Studio, PhpStorm, Netbeans, Intellij Idea, Zend Studio.Operating Systems: Microsoft Windows, GNU/Linux.Methodologies & Standards: Scrum, RUP, XP, DIRKS, ISAD (G), ISO 15489.\n",
      "ExperienceSoftware Developer,04/2016-09/2016–Peoria,,EcuadorModeled process using BPM, workflows for a Help Desk Module in Alfresco Activiti BPM.Designed and created de Alfresco Content Model for the Help Desk Module.Developed using XML, Javascript, Alfresco REST Web Services, jQuery, Bootstrap and Freemarker the workflows modeled.Integrated Alfresco ECM with Microsoft Office and WebDav protocol.Software .Net Developer,01/2015-04/2016–City,,EcuadorDeveloped using C#, ASP.NET MVC, ASP.NET Web API, ADO.NET .NET Framework, EF, LINQ, SQL Server, Hangfire, SignalR, MS SQL Server, T-SQL, AngularJS, jQuery, HTML5, CSS3, and MySQL a large-scale parking system from scratch.Rewrote and redesigned a poorly parking system implemented in Node.js.Rewrote the entire backend in C# and the frontend in ASP.NET MVC, ASP.NET Web API, AngularJS, jQuery, JavaScript, and Bootstrap to be more user friendly.Developed using Hangfire to perform with .NET job scheduling, and SignalR to create a real-time application which allowed bi-directional communication between server and client.Created a sync job which listened to the records of a sensor in a MySQL database and synchronized them in a MS SQL Server database and showed real-time results in a dashboard.Developed using PHP, JasperReports for PHP REST Web Service API, MySQL, AngularJS, jQuery, HTML5, CSS3 and, Bootstrap a Report Module to integrate it into a police management system.Coded using PL/pgSQL several queries to compare and recover millions of damaged records.Software Engineer and Professor,09/2008-11/2014Newport Group–City,,CubaDeveloped using PHP5, HTML, CSS, JavaScript, Drupal, jQuery, AJAX, JSON, MySQL and, XML-RPC an Intranet.Developed using Alfresco ECM, Alfresco REST API, PHP, XML, HTML, CSS, JavaScript, CodeIgniter, jQuery, PostgreSQL and, Lucene the modules File Sharing and Audit Log for a Document Management System.Integrated Alfresco ECM with OpenOffice.org.Developed using PHP, HTML5, CSS3, JavaScript, jQuery, AJAX, JSON, and, PostgreSQL the Dashboard and Report Management modules.Developed using Alfresco ECM, Activiti, REST Web Services, Freemarker, HTML, CSS3, LESS CSS, JavaScript, jQuery, AJAX, JSON PostgreSQL and, Lucene the modules Records Management, Classification Table Management, Task Management, Data List, Dashboard and, Project Files Management for different versions of a Document Management System.Performed Requirements Specification, Analysis and Design, and Test Case Design.Customized using Freemarker, Bootstrap, LESS CSS, XML and, JavaScript a Theme for Alfresco Share.Coded using XML, Content Models for Alfresco ECM.Interacted with clients to identify Business Requirements.Provided training courses for clients.Products and projects:\n",
      "Product: Document Management System eXcriba v3.0 (2013-2014, Patent 2127-7-2014).Client: Development Centers of University of Informatics Sciences, Havana Cuba.Product: Quipus, Document Management System v1.0 (2012-2013, Patent 196-2012).Client: General Archive of the Nation of Venezuela.Product: Document Management System AvilaDOC (2009-2010).Client: Ministry of Interior and Justice of Venezuela.Product: Document Management System eXcriba v1.0 (2008-2010, Patent 2868-2010), v2.0 (2010-2011, Patent 2378-2011).Client: Development Centers of University of Informatics Sciences, Havana Cuba.Client: General Customs of the Republic of Cuba.Client: Ministry of Informatics and Communications of Cuba.\n",
      "EducationBS:Computer Science,Expected in2008-University of Informatics Sciences-Havana,GPA:Status-Computer ScienceDegree:Accounting,Expected in2003-Higher Pedagogical Institute-,GuantanamoGPA:Status-Accounting\n",
      "Skills.NET, ASP.NET, ADO, AJAX, Apache, Apache Web Server, API, bi, Content, CSS, CSS3, Client, clients, Databases, database, Document Management, Drupal, English, XML, Help Desk, HTML, HTML5, PHP, PHP5, ISO, JavaScript, jQuery, JSON, Linux, C#, Microsoft Office, Microsoft Windows, MVC, MySQL, Composer, OCR, Operating Systems, PL, police, PostgreSQL, Programming, Project Management, real-time, RUP, scheduling, Scrum, SOAP, Software Engineering, Spanish, Specification, MS SQL Server, SQL Server, System v1.0, Tomcat, T-SQL, Visual Studio\n"
     ]
    }
   ],
   "source": [
    "print(df['resume_text'].iloc[6240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9e7d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume = parse_with_llm(df['resume_text'].iloc[6239], resume_prompt_template, resume_parser, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73d61c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": null,\n",
      "  \"location_preference\": null,\n",
      "  \"work_authorization\": null,\n",
      "  \"employment_type_preference\": null,\n",
      "  \"hard_skills\": [\n",
      "    \"ATM\",\n",
      "    \"Broadband\",\n",
      "    \"C\",\n",
      "    \"Cables\",\n",
      "    \"Cisco Routers\",\n",
      "    \"Citrix\",\n",
      "    \"Dispatching\",\n",
      "    \"Ethernet\",\n",
      "    \"Flash\",\n",
      "    \"Frame Relay\",\n",
      "    \"GSM\",\n",
      "    \"HP OpenView\",\n",
      "    \"Inventory\",\n",
      "    \"IP\",\n",
      "    \"ISIS\",\n",
      "    \"Office\",\n",
      "    \"Word\",\n",
      "    \"MSN\",\n",
      "    \"Network\",\n",
      "    \"Networks\",\n",
      "    \"Quality\",\n",
      "    \"Siemens\",\n",
      "    \"Switches\",\n",
      "    \"T1\",\n",
      "    \"Troubleshooting\",\n",
      "    \"UMTS\",\n",
      "    \"Upgrades\",\n",
      "    \"VPN\",\n",
      "    \"T3\",\n",
      "    \"OC3\",\n",
      "    \"OC12\",\n",
      "    \"OC48\",\n",
      "    \"OC192\",\n",
      "    \"FastEthernet\",\n",
      "    \"GigE\",\n",
      "    \"MPLS\",\n",
      "    \"DIA\",\n",
      "    \"Tellabs 5500\",\n",
      "    \"5320\",\n",
      "    \"532L\",\n",
      "    \"Alcatel 1630\",\n",
      "    \"1631\",\n",
      "    \"1671\",\n",
      "    \"1677\",\n",
      "    \"Ericsson UMTS/GSM\",\n",
      "    \"Lucent UMTS\",\n",
      "    \"Nokia GSM\",\n",
      "    \"DACS\",\n",
      "    \"MUXES\",\n",
      "    \"DDM2000\",\n",
      "    \"DMX\",\n",
      "    \"FLM150\",\n",
      "    \"FT2000\",\n",
      "    \"Fujitsu\",\n",
      "    \"5E\",\n",
      "    \"DMS\",\n",
      "    \"WFA-C/DI/DO\",\n",
      "    \"GRETA\",\n",
      "    \"REACT\",\n",
      "    \"INTAS\",\n",
      "    \"NMA\",\n",
      "    \"BOCRIS\",\n",
      "    \"DBSCID\",\n",
      "    \"TIRKS\",\n",
      "    \"TEMS\",\n",
      "    \"ACTS\",\n",
      "    \"EXACT\",\n",
      "    \"MSOC\",\n",
      "    \"SARTS\",\n",
      "    \"NetAnalyst\",\n",
      "    \"Granite\",\n",
      "    \"WebXng\",\n",
      "    \"AOTS\",\n",
      "    \"IWOS\",\n",
      "    \"UTrack\",\n",
      "    \"Trifecta\",\n",
      "    \"CTS\",\n",
      "    \"Putty\",\n",
      "    \"MRIM\",\n",
      "    \"ESNAP\",\n",
      "    \"E-PADD\",\n",
      "    \"ECRM\",\n",
      "    \"Go Global\",\n",
      "    \"Smarts\",\n",
      "    \"Expedio\",\n",
      "    \"Chameleon\",\n",
      "    \"Circuit Id Finder\",\n",
      "    \"Didgeridoo\",\n",
      "    \"Freya\",\n",
      "    \"MPLS Diagnostic Tool\",\n",
      "    \"Flash GBS\",\n",
      "    \"Appeal\",\n",
      "    \"Remedy\",\n",
      "    \"Site Locator\",\n",
      "    \"Greta\",\n",
      "    \"EBTA\",\n",
      "    \"VTAG\",\n",
      "    \"CEMR\",\n",
      "    \"BERT\"\n",
      "  ],\n",
      "  \"soft_skills\": [\n",
      "    \"Prioritization\",\n",
      "    \"Multi-tasking\",\n",
      "    \"Quick Learning\",\n",
      "    \"Independent Work\",\n",
      "    \"Teamwork\",\n",
      "    \"Guest Services\",\n",
      "    \"Inventory Control\",\n",
      "    \"Merchandising\",\n",
      "    \"Loss Prevention\",\n",
      "    \"Cash Register Operations\",\n",
      "    \"Product Promotions\"\n",
      "  ],\n",
      "  \"languages\": [],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"role\": \"Network Engineer/Designer\",\n",
      "      \"company\": \"Intuitive Surgical\",\n",
      "      \"date_start\": \"2011-04-01T00:00:00\",\n",
      "      \"date_end\": \"2013-05-01T00:00:00\",\n",
      "      \"role_description\": \"Created T1 and T3 segments and paths for UMTS designs; created Granite Work Orders.Performed cleanup for MSPP Bypass by removing cross connects from the 1678 DACS and deleting VLANs from the ES64 card.Issued CIQ's for the disconnection of Ericsson and Lucent T1's and Lucent T3's for AT&T network upgrades to Ethernet; provides specific information for T1's such as the RNCs, Node Bs, MSNs, and OC3 info and specific information for T3's such as the VCs, MSNs, SIAD and OAM info, by accessing the MSN.Verified the cross connect information on CIQs matched the information in NetAnalyst; made corrections accordingly.Tracked all T1 and T3 CIQ rejections to verify sites were resubmitted in a timely manner; created daily T1 rejection report; updated and submitted a weekly T3 tracker with statuses on all sites.Created and submitted work orders for T1 disconnections using IWOS.Submitted and closed trouble tickets for T1 disconnections using CTS.Deleted T1 paths and segments, in Granite, for the purpose of system clean up and archiving.Updated MRIM with site names, pertinent dates and statuses.Prepared circuits for re-homes by verifying and/or inputting new DACS cross connects; verified ports were in service and provisioned; monitored new DACS cross connect, at cut point, for traffic.Loaded ET-MFX cards and NTE equipment; loaded IP addresses and other information into SIADs; built cables, segments, Ethernet paths (Node B to SIAD), 1GIGE paths (SIAD to IPAG), and child and parent paths (IPAG to RNC) for Ethernet designs.Used various systems such as NetAnalyst, Granite, WebXng, AOTS, IWOS, UTrack, Trifecta, CTS, Putty, MRIM, ESNAP, E-PADD, ECRM, Citrix, and Go Global.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Service Operations Technician\",\n",
      "      \"company\": \"The Kraft Heinz Company\",\n",
      "      \"date_start\": \"2010-10-01T00:00:00\",\n",
      "      \"date_end\": \"2011-04-01T00:00:00\",\n",
      "      \"role_description\": \"Provided 24x7 first line support by initiating corrective actions to resolve problems with customer products and equipment.Responsible for opening, tracking, updating and escalating trouble tickets to ensure timely restoration of services, as well as keeping the customer informed.Responsible for proactively monitoring customer networks and equipment to respond accurately and quickly to alarms.Responsible for troubleshooting the customers equipment on T1/E1, T3/E3, OC3, OC12, OC48, OC192, FastEthernet and GigE circuits on the various platforms of MPLS, ATM, FRAME RELAY, DIA and VPN.Responsible for logging into Cisco routers to verify status, identifying problems and assisting customers with trouble isolation by performing loop test, ping test and performing trace routes.Use various systems such as HP OpenView, Smarts, Expedio, ISIS, Chameleon, Circuit Id Finder, Didgeridoo, Freya, MPLS Diagnostic Tool, Flash GBS, Appeal.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Network Control Engineer\",\n",
      "      \"company\": \"TEKsystems/AT&T\",\n",
      "      \"date_start\": \"2010-07-01T00:00:00\",\n",
      "      \"date_end\": \"2010-10-01T00:00:00\",\n",
      "      \"role_description\": \"Assisted customers/vendors in the maintenance of broadband services in a 24x7 environment.Received customer trouble reports, analyzed, isolated troubles and directed the restoration of service by tracking, updating and escalating trouble tickets.Tested and assisted customers with troubleshooting their equipment on T1, T3, OC3, OC12, OC48, OC192, GigE, and MetroE circuits.Worked in various pieces of equipment such as Tellabs 5500, 5320, 532L, Alcatel 1630, 1631, 1671, 1677 with TL1 command knowledge.Experience with Ericsson UMTS/GSM, Lucent UMTS, Nokia GSM and Siemens GSM.Used various systems such as Remedy, Site Locator, NetAnalyst, Granite Inventory, WebXng, Greta, EBTA, VTAG, CEMR, BERT.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Electronic Technician\",\n",
      "      \"company\": \"ATT\",\n",
      "      \"date_start\": \"2001-02-01T00:00:00\",\n",
      "      \"date_end\": \"2009-10-01T00:00:00\",\n",
      "      \"role_description\": \"Assisted in the installation, testing and adjusting of equipment and facilities used in providing high quality broadband switching networks and special services.Installed T1, T3, OC3, OC12, OC48, OC192, DSO - DS3 and MetroE circuits; tested with field techs, central office techs and customers when necessary.Reviewed and analyzed word documents in performing network operations.Made routine design changes to circuit paths when needed to ensure installation of high quality broadband services.Worked in various pieces of equipment such as MUXES (DDM2000, DMX, FLM150, FT2000, Fujitsu), DACS' (Alcatels, Tellabs, DACS4, DX1, DAC2), and switches (5E, DMS).Systems used include WFA-C/DI/DO, GRETA, REACT, INTAS, NMA, BOCRIS, DBSCID, TIRKS, TEMS, ACTS, EXACT, MSOC, SARTS.Routinely completed DACS and MUX mapping and placed DACS and MUX loops for continuity verification and to isolate and resolve continuity problems.Managed, coordinated and performed facility grooms-DACS cuts and office assisted; followed up   with, resolved and completed failed facility grooms.Coordinated the dispatching of field techs to various locations for installation and troubleshooting.\"\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Science\",\n",
      "      \"institution\": \"Marshall University\",\n",
      "      \"date_start\": \"1997-07-01T00:00:00\",\n",
      "      \"date_end\": null,\n",
      "      \"grade\": null,\n",
      "      \"description\": null\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_resume.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143dea9a",
   "metadata": {},
   "source": [
    "### Parse job desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b7e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "Hope you are doing great today. Please find the job description below. Let me know your job interest as soon as possible. I will highly appreciate it if you can refer somebody suitable for this position. \n",
      "Role: Data Engineer (Oracle and DataStage).Location: RemoteContract Position\n",
      "Job Description:RoleResponsibilities:Skills: Oracle, Datastage, UNIX, PLSQL, SQL. Good to have: AWS, Matillion, Snowflake. Data engineering experience; expert level experience with SQL. Experience with the cloud (AWS, Azure andor Google Cloud Platform).  Experience in cloud-based data warehouses (Snowflake, Google BigQuery, Amazon Redshift, Azure Synapse Analytics).  Experience with cloud-based ETLELT tools (Matillion, Glue, Data Factory) and data modelling.  Experience with version control systems (Git, SVN).  Understanding of and willingness to embrace Agile Principles. \n",
      "Looking forward to your response . \n",
      "Shubhanshu Tripathishubhanshu.t@cblsolutions.com 469-947-7816 (Ext  209)Cerebral Technologies, Inc (D.B.A CBLSolutions) http:cblsolutions.com400 E Royal Lane, Ste 235, Irving, TX - 75039 Linkedin: https:www.linkedin.cominshubhanshu-tripathi-058228213 \n"
     ]
    }
   ],
   "source": [
    "print(df['job_description_text'].iloc[6236])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57dd896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_jd = parse_with_llm(df['job_description_text'].iloc[6236], jd_prompt_template, jd_parser, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3fefe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"company_name\": \"Cerebral Technologies, Inc\",\n",
      "  \"role_title\": \"Data Engineer\",\n",
      "  \"employment_type\": \"Contract\",\n",
      "  \"about_the_company\": null,\n",
      "  \"job_responsibilities\": [],\n",
      "  \"required_hard_skills\": [\n",
      "    \"Oracle\",\n",
      "    \"Datastage\",\n",
      "    \"UNIX\",\n",
      "    \"PLSQL\",\n",
      "    \"SQL\",\n",
      "    \"AWS\",\n",
      "    \"Matillion\",\n",
      "    \"Snowflake\",\n",
      "    \"AWS\",\n",
      "    \"Azure\",\n",
      "    \"Google Cloud Platform\",\n",
      "    \"Snowflake\",\n",
      "    \"Google BigQuery\",\n",
      "    \"Amazon Redshift\",\n",
      "    \"Azure Synapse Analytics\",\n",
      "    \"Matillion\",\n",
      "    \"Glue\",\n",
      "    \"Data Factory\",\n",
      "    \"Git\",\n",
      "    \"SVN\",\n",
      "    \"SQL\"\n",
      "  ],\n",
      "  \"required_soft_skills\": [\n",
      "    \"Agile Principles\"\n",
      "  ],\n",
      "  \"required_language_proficiencies\": [],\n",
      "  \"required_work_authorization\": null,\n",
      "  \"required_education\": null,\n",
      "  \"job_location\": \"Remote\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_jd.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b71f4",
   "metadata": {},
   "source": [
    "### Parse & save into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5fbce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_text</th>\n",
       "      <th>job_description_text</th>\n",
       "      <th>label</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SummaryHighly motivated Sales Associate with e...</td>\n",
       "      <td>Net2Source Inc. is an award-winning total work...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>RES_QDvgj241</td>\n",
       "      <td>JD_QDvgj241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional SummaryCurrently working with Cat...</td>\n",
       "      <td>At Salas OBrien we tell our clients that were ...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-06-09</td>\n",
       "      <td>RES_tvKW28PW</td>\n",
       "      <td>JD_tvKW28PW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SummaryI started my construction career in Jun...</td>\n",
       "      <td>Schweitzer Engineering Laboratories (SEL) Infr...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>RES_Pg6ipOr5</td>\n",
       "      <td>JD_Pg6ipOr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SummaryCertified Electrical Foremanwith thirte...</td>\n",
       "      <td>Mizick Miller &amp; Company, Inc. is looking for a...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>RES_O5bebNRA</td>\n",
       "      <td>JD_O5bebNRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SummaryWith extensive experience in business/r...</td>\n",
       "      <td>Life at Capgemini\\nCapgemini supports all aspe...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>RES_JWSvWYY5</td>\n",
       "      <td>JD_JWSvWYY5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6236</th>\n",
       "      <td>SummaryResults-driven Data Entry Clerk with ex...</td>\n",
       "      <td>Hi,\\nHope you are doing great today. Please fi...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>RES_vNEJ62Py</td>\n",
       "      <td>JD_vNEJ62Py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6237</th>\n",
       "      <td>Professional SummaryWith the attitude of learn...</td>\n",
       "      <td>Job Title: DHT - Front End Software Engineer W...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>RES_DPqh0lVb</td>\n",
       "      <td>JD_DPqh0lVb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6238</th>\n",
       "      <td>Summary•        \\nOver\\nThree years of extensi...</td>\n",
       "      <td>LHH Recruitment Solutions is looking for a Sof...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>RES_1HWrRA5T</td>\n",
       "      <td>JD_1HWrRA5T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>ProfileAbility to prioritize and multi-task in...</td>\n",
       "      <td>Our client is a growing Medical Device company...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>RES_XdUNowSD</td>\n",
       "      <td>JD_XdUNowSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>SummaryFull stack Software Engineer with 8+ ye...</td>\n",
       "      <td>Robert Half is looking for a Senior Full Stack...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>RES_2RPwzELC</td>\n",
       "      <td>JD_2RPwzELC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            resume_text  \\\n",
       "0     SummaryHighly motivated Sales Associate with e...   \n",
       "1     Professional SummaryCurrently working with Cat...   \n",
       "2     SummaryI started my construction career in Jun...   \n",
       "3     SummaryCertified Electrical Foremanwith thirte...   \n",
       "4     SummaryWith extensive experience in business/r...   \n",
       "6236  SummaryResults-driven Data Entry Clerk with ex...   \n",
       "6237  Professional SummaryWith the attitude of learn...   \n",
       "6238  Summary•        \\nOver\\nThree years of extensi...   \n",
       "6239  ProfileAbility to prioritize and multi-task in...   \n",
       "6240  SummaryFull stack Software Engineer with 8+ ye...   \n",
       "\n",
       "                                   job_description_text     label  \\\n",
       "0     Net2Source Inc. is an award-winning total work...    No Fit   \n",
       "1     At Salas OBrien we tell our clients that were ...    No Fit   \n",
       "2     Schweitzer Engineering Laboratories (SEL) Infr...    No Fit   \n",
       "3     Mizick Miller & Company, Inc. is looking for a...    No Fit   \n",
       "4     Life at Capgemini\\nCapgemini supports all aspe...    No Fit   \n",
       "6236  Hi,\\nHope you are doing great today. Please fi...  Good Fit   \n",
       "6237  Job Title: DHT - Front End Software Engineer W...  Good Fit   \n",
       "6238  LHH Recruitment Solutions is looking for a Sof...  Good Fit   \n",
       "6239  Our client is a growing Medical Device company...  Good Fit   \n",
       "6240  Robert Half is looking for a Senior Full Stack...  Good Fit   \n",
       "\n",
       "     snapshot_date     resume_id       job_id  \n",
       "0       2024-10-10  RES_QDvgj241  JD_QDvgj241  \n",
       "1       2024-06-09  RES_tvKW28PW  JD_tvKW28PW  \n",
       "2       2024-11-10  RES_Pg6ipOr5  JD_Pg6ipOr5  \n",
       "3       2024-09-12  RES_O5bebNRA  JD_O5bebNRA  \n",
       "4       2024-02-04  RES_JWSvWYY5  JD_JWSvWYY5  \n",
       "6236    2024-06-02  RES_vNEJ62Py  JD_vNEJ62Py  \n",
       "6237    2024-09-01  RES_DPqh0lVb  JD_DPqh0lVb  \n",
       "6238    2024-11-02  RES_1HWrRA5T  JD_1HWrRA5T  \n",
       "6239    2024-07-26  RES_XdUNowSD  JD_XdUNowSD  \n",
       "6240    2024-08-22  RES_2RPwzELC  JD_2RPwzELC  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = pd.concat([df[:5], df[-5:]])\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616c186f",
   "metadata": {},
   "source": [
    "Parse JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b24e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:45<00:00, 10.51s/it]\n"
     ]
    }
   ],
   "source": [
    "parsed_resumes = []\n",
    "parsed_jds = []\n",
    "\n",
    "for idx, row in tqdm(df_subset.iterrows(), total=len(df_subset)):\n",
    "    resume_text = row['resume_text']\n",
    "    jd_text = row['job_description_text']\n",
    "    try:\n",
    "        # Process resume\n",
    "        parsed_resume = parse_with_llm(resume_text, resume_prompt_template, resume_parser, llm)\n",
    "        parsed_resume_dict = parsed_resume.model_dump(mode=\"json\")\n",
    "        parsed_resume_dict = {**parsed_resume_dict, \n",
    "                              'snapshot_date': row['snapshot_date'], \n",
    "                              'id': row['resume_id']}\n",
    "        parsed_resumes.append(parsed_resume_dict)\n",
    "\n",
    "        # Process JD\n",
    "        parsed_jd = parse_with_llm(jd_text, jd_prompt_template, jd_parser, llm)\n",
    "        parsed_jd_dict = parsed_jd.model_dump(mode=\"json\")\n",
    "        parsed_jd_dict = {**parsed_jd_dict, \n",
    "                          'snapshot_date': row['snapshot_date'],\n",
    "                          'id': row['job_id']}\n",
    "        parsed_jds.append(parsed_jd_dict)\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing row {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3d83a",
   "metadata": {},
   "source": [
    "Convert into PySpark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "903ec600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_type_to_spark_type(annotation):\n",
    "    origin = get_origin(annotation)\n",
    "\n",
    "    if origin is Union:  # Handle Optional\n",
    "        args = [arg for arg in get_args(annotation) if arg is not type(None)]\n",
    "        return python_type_to_spark_type(args[0])\n",
    "\n",
    "    if origin in (list, List):\n",
    "        element_type = python_type_to_spark_type(get_args(annotation)[0])\n",
    "        return ArrayType(element_type)\n",
    "\n",
    "    if isinstance(annotation, type):\n",
    "        if issubclass(annotation, BaseModel):\n",
    "            return pydantic_to_spark_schema(annotation)\n",
    "        if issubclass(annotation, str):\n",
    "            return StringType()\n",
    "        if issubclass(annotation, int):\n",
    "            return IntegerType()\n",
    "        if issubclass(annotation, float):\n",
    "            return FloatType()\n",
    "        if issubclass(annotation, bool):\n",
    "            return BooleanType()\n",
    "        if issubclass(annotation, datetime.datetime):\n",
    "            return StringType()\n",
    "\n",
    "    return StringType()\n",
    "\n",
    "def pydantic_to_spark_schema(model: type) -> StructType:\n",
    "    fields = []\n",
    "\n",
    "    for name, field in model.model_fields.items():\n",
    "        annotation = field.annotation\n",
    "\n",
    "        spark_type = python_type_to_spark_type(annotation)\n",
    "        fields.append(StructField(name, spark_type, True))  # assume all nullable\n",
    "    fields.append(StructField('snapshot_date', StringType(), True))\n",
    "    fields.append(StructField('id', StringType(), True))\n",
    "\n",
    "    return StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "30d87e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = spark.createDataFrame(parsed_resumes, schema=pydantic_to_spark_schema(Resume)).repartition(\"snapshot_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c0b2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_df = spark.createDataFrame(parsed_jds, schema=pydantic_to_spark_schema(JD)).repartition(\"snapshot_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53be5a",
   "metadata": {},
   "source": [
    "Save into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "753e182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "resume_df.write.format(\"mongodb\") \\\n",
    "               .mode(\"overwrite\") \\\n",
    "               .option(\"database\", \"jobmirror\") \\\n",
    "               .option(\"collection\", \"resume\") \\\n",
    "               .partitionBy(\"snapshot_date\") \\\n",
    "               .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c7686bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jd_df.write.format(\"mongodb\") \\\n",
    "               .mode(\"overwrite\") \\\n",
    "               .option(\"database\", \"jobmirror\") \\\n",
    "               .option(\"collection\", \"jd\") \\\n",
    "               .partitionBy(\"snapshot_date\") \\\n",
    "               .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f185d77",
   "metadata": {},
   "source": [
    "# SILVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a8a66",
   "metadata": {},
   "source": [
    "# GOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5416e",
   "metadata": {},
   "source": [
    "## Get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52d6567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f948ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_required_skills = embedding_model.embed_documents(parsed_jd.required_hard_skills)\n",
    "embeddings_skills_owned = embedding_model.embed_documents(parsed_resume.hard_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93af6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_skills = np.array(embeddings_required_skills)\n",
    "skills_owned = np.array(embeddings_skills_owned)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "required_skills = required_skills / np.linalg.norm(required_skills, axis=1, keepdims=True)\n",
    "skills_owned = skills_owned / np.linalg.norm(skills_owned, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(required_skills, skills_owned.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ae5fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required: PostgreSQL  <=> Best Owned: PostgreSQL  | Similarity: 1.00\n",
      "Required: Express  <=> Best Owned: EF  | Similarity: 0.63\n",
      "Required: React  <=> Best Owned: HTML5  | Similarity: 0.63\n",
      "Required: NodeJS  <=> Best Owned: AngularJS  | Similarity: 0.73\n",
      "Required: Redux  <=> Best Owned: Redmine  | Similarity: 0.63\n",
      "Required: HTML  <=> Best Owned: HTML  | Similarity: 1.00\n",
      "Required: CSS  <=> Best Owned: CSS  | Similarity: 1.00\n",
      "Required: JavaScript  <=> Best Owned: jQuery  | Similarity: 0.86\n",
      "Required: JSON  <=> Best Owned: JSON  | Similarity: 1.00\n",
      "Required: Git  <=> Best Owned: GIT  | Similarity: 0.95\n",
      "Required: REST  <=> Best Owned: REST  | Similarity: 1.00\n",
      "Required: Firebase  <=> Best Owned: Hangfire  | Similarity: 0.62\n",
      "Required: Material-UI  <=> Best Owned: AngularJS  | Similarity: 0.63\n",
      "Required: D3js  <=> Best Owned: jQuery  | Similarity: 0.72\n",
      "Required: Docker (Compose)  <=> Best Owned: Composer  | Similarity: 0.67\n",
      "Required: AWS  <=> Best Owned: AWS EC2  | Similarity: 0.85\n"
     ]
    }
   ],
   "source": [
    "best_matches = []\n",
    "\n",
    "for i, req_skill in enumerate(parsed_jd.required_hard_skills):\n",
    "    j = similarity_matrix[i].argmax()\n",
    "    score = similarity_matrix[i, j]\n",
    "    if score >= 0.6:\n",
    "        best_matches.append((req_skill, parsed_resume.hard_skills[j], score))\n",
    "\n",
    "# Print\n",
    "for req_skill, own_skill, score in best_matches:\n",
    "    print(f\"Required: {req_skill}  <=> Best Owned: {own_skill}  | Similarity: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "991dbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_role_name = embedding_model.embed_query(parsed_jd.role_title)\n",
    "embeddings_experience_titles = embedding_model.embed_documents([exp.role for exp in parsed_resume.experience])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65b9e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Full Stack Engineer (PERN Stack)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_jd.role_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4e5d683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Software Developer',\n",
       " 'Software .Net Developer',\n",
       " 'Software Engineer and Professor']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[exp.role for exp in parsed_resume.experience]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31d693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = np.array(embeddings_role_name)\n",
    "experiences = np.array(embeddings_experience_titles)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "role_name = role_name / np.linalg.norm(role_name)\n",
    "experiences = experiences / np.linalg.norm(experiences, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(experiences, role_name.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5a979df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65028087, 0.62905722, 0.6121288 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
