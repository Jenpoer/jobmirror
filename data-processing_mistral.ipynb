{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffce314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import dateparser\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "from mistralai import Mistral\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, get_origin, get_args, Union\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, FloatType, BooleanType, TimestampType, StructField, StructType\n",
    "\n",
    "from utils.mongodb_utils import read_bronze_table_as_pyspark, read_bronze_table_as_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bddc93",
   "metadata": {},
   "source": [
    "# SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15322ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cnamuangtoun/resume-job-description-fit\")\n",
    "df = dataset[\"train\"].to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf38c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"MISTRAL_API_KEY\"] = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91b2920-fae1-41e2-a379-688a6a23bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral = Mistral(api_key=os.environ.get(\"MISTRAL_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09600e-cc2b-49e4-bdc1-85d9111b8f99",
   "metadata": {},
   "source": [
    "Generate random snapshot dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b7f880-f9dc-48c3-8ff6-b9e6020e35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seeded Generator\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# Define start and end date\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "end_date = pd.to_datetime('2025-01-01')\n",
    "\n",
    "# Generate random timestamps between start_date and end_date\n",
    "random_dates = pd.to_datetime(\n",
    "    rng.uniform(start_date.value, end_date.value, size=len(df))\n",
    ")\n",
    "\n",
    "# Ensure it's treated as a pandas Series and convert to date\n",
    "df['snapshot_date'] = pd.Series(random_dates).dt.date  # This will convert to date format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66030faf-5e3d-41f8-b884-6c6897952e6d",
   "metadata": {},
   "source": [
    "Generate random IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff68f2a-f7a7-4d7c-86e5-83c0c515bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_id(prefix: str, length=8, use_digits=True, use_letters=True, seed=42):\n",
    "    rng = np.random.default_rng(seed=seed) \n",
    "\n",
    "    characters = ''\n",
    "    \n",
    "    if use_digits:\n",
    "        characters += string.digits\n",
    "    if use_letters:\n",
    "        characters += string.ascii_letters\n",
    "\n",
    "    # Ensure we have characters to choose from\n",
    "    if not characters:\n",
    "        raise ValueError(\"At least one of 'use_digits' or 'use_letters' must be True.\")\n",
    "    \n",
    "    # Use np.random.choice to randomly select characters\n",
    "    random_id = ''.join(rng.choice(list(characters), size=length))\n",
    "    return prefix + random_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c65ff97-0bb5-4151-8a0d-2ddac097bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resume_id'] = df.apply(lambda row: generate_random_id('RES_', seed=row.name), axis=1)\n",
    "df['job_id'] = df.apply(lambda row: generate_random_id('JD_', seed=row.name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc7cc9",
   "metadata": {},
   "source": [
    "# BRONZE TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edbf69",
   "metadata": {},
   "source": [
    "## Resume Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4dca9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "    \n",
    "class Experience(BaseModel):\n",
    "    role: Optional[str] = Field(None, description=\"The job title or position held\")\n",
    "    company: Optional[str] = Field(None, description=\"The name of the company. Exclude other description or location\")\n",
    "    date_start: Optional[str] = Field(None, description=\"The start date of the job. Dates must be in ISO 8601 format (YYYY-MM-DDTHH:MM:SS) or use the keywords 'present', 'current', or 'ongoing'\")\n",
    "    date_end: Optional[str] = Field(None, description=\"The end date of the job. Dates must be in ISO 8601 format (YYYY-MM-DDTHH:MM:SS) or use the keywords 'present', 'current', or 'ongoing'\")\n",
    "    role_description: Optional[str] = Field(None, description=\"A description of the responsibilities and achievements in the role\")\n",
    "\n",
    "class Education(BaseModel):\n",
    "    degree: Optional[str] = Field(None, description=\"The academic degree obtained\")\n",
    "    institution: Optional[str] = Field(None, description=\"The name of the educational institution\")\n",
    "    date_start: Optional[str] = Field(None, description=\"The start date of the education program. Dates must be in ISO 8601 format (YYYY-MM-DDTHH:MM:SS) or use the keywords 'present', 'current', or 'ongoing'\")\n",
    "    date_end: Optional[str] = Field(None, description=\"The end date of the education program. Dates must be in ISO 8601 format (YYYY-MM-DDTHH:MM:SS) or use the keywords 'present', 'current', or 'ongoing'\")\n",
    "    grade: Optional[float] = Field(None, description=\"The GPA or final grade, if available\")\n",
    "    description: Optional[str] = Field(None, description=\"Additional details about the education\")\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    name: Optional[str] = Field(None, description=\"Full name of the person\")\n",
    "    location_preference: Optional[str] = Field(None, description=\"Preference for their work location / remote, if stated\")\n",
    "    work_authorizaton: Optional[str] = Field(None, description=\"Work authorization that the person holds, such as citizenship, if stated\")\n",
    "    employment_type_preference: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Type of employment the resume is looking for such as Full-time, Part-time, Contract, Freelance, or Internship, if stated. It can also be a preference for remote work or on-site work\"\n",
    "    )\n",
    "    hard_skills: List[str] = Field(default_factory=list, description=\"A list of hard or technical skills mentioned in the resume. All hard skills are tools, frameworks, or programming languages (e.g., Python, TensorFlow, Docker). Keep it as keywwords. Exclude certification or license\")\n",
    "    soft_skills: List[str] = Field(default_factory=list, description=\"A list of soft skills mentioned in the resume. Soft skills are qualities like communication, teamwork, leadership. Keep it as keywwords. Exclude required languages\")\n",
    "    languages: List[str]= Field(default_factory=list, description=\"A list of language proficiencies mentioned in the resume. If the resume does not mention any languages, then fill this with the language that the resume is written in\")\n",
    "    experience: List[Experience] = Field(default_factory=list, description=\"A list of past work experiences in reverse chronological order (most recent first).\")\n",
    "    education: List[Education] = Field(default_factory=list, description=\"A list of educational qualifications\")\n",
    "    certifications: List[str] = Field(default_factory=list, description=\"A list of certifications or licenses related with hard skills, medical skills, and software tools mentioned in the resume. For example, AWS Certified Solutions Architect, PMP, etc. Certifications must exclude any work role IDs, only include valid licenses or certifications.\")\n",
    "\n",
    "# Create the parser\n",
    "resume_parser = PydanticOutputParser(pydantic_object=Resume)\n",
    "format_instructions = resume_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7233d",
   "metadata": {},
   "source": [
    "## Job Desc Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f413bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models for job desc\n",
    "\n",
    "class JD(BaseModel):\n",
    "    company_name: Optional[str] = Field(None, description=\"Name of the company posting the job\")\n",
    "    role_title: Optional[str] = Field(None, description=\"Job title or position being offered\")\n",
    "    application_deadline: Optional[str] = Field(None, description=\"The deadline for submitting applications. Dates must be in ISO 8601 format (YYYY-MM-DDTHH:MM:SS)\")\n",
    "    date_posted: Optional[str] = Field(None, description=\"The date when the job was posted. Dates must be in ISO 8601 format (YYYY-MM-DDTHH:MM:SS)\")\n",
    "    employment_type: Optional[str] = Field(None, description=\"Type of employment, such as Full-time, Part-time, Contract, Freelance, or Internship. If not stated, it is assumed to be Full-time\")\n",
    "    about_the_company: Optional[str] = Field(None, description=\"A brief overview or description of the company\")\n",
    "    job_responsibilities: List[str] = Field(default_factory=list, description=\"A list of key duties, tasks, or responsibilities associated with the job\")\n",
    "    required_hard_skills: List[str] = Field(default_factory=list, description=\"A list of technical or hard skills required or preferred for the job. Keep it as keywords. This includes programming languages, software tools, or frameworks like Python, Java, SQL\")\n",
    "    required_soft_skills: List[str] = Field(default_factory=list, description=\"A list of soft skills or character required or preferred for the job. Keep it as keywords. This includes communication, teamwork, or leadership skills\")   \n",
    "    required_language_proficiencies: List[str] = Field(default_factory=list, description=\"A list of language proficiencies required for the job if stated. If the job description does not mention any languages, then fill this with the language that the job description is written in\")\n",
    "    required_education: Optional[str] = Field(None, description=\"The minimum educational qualification required for the job, such as a degree or certification\")\n",
    "    required_work_authorization: Optional[str] = Field(None, description=\"Work authorization required for the job\")\n",
    "    job_location: Optional[str] = Field(None, description=\"Location where the job is based, such as a city or remote\")\n",
    "    certifications: List[str] = Field(default_factory=list, description=\"A list of certifications or licenses related with hard skills, medical skills, and software tools mentioned in the resume. certifications should relate only to verifiable credentials (e.g., AWS, CISSP, PMP). Do not include work roles or job titles as certifications\")\n",
    "    \n",
    "# Create the parser\n",
    "jd_parser = PydanticOutputParser(pydantic_object=JD)\n",
    "format_instructions = jd_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2cac6",
   "metadata": {},
   "source": [
    "## Parse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb440d",
   "metadata": {},
   "source": [
    "### Parse resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8aa5a5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ministral-3b-2410\n",
      "ministral-3b-latest\n",
      "ministral-8b-2410\n",
      "ministral-8b-latest\n",
      "open-mistral-7b\n",
      "mistral-tiny\n",
      "mistral-tiny-2312\n",
      "open-mistral-nemo\n",
      "open-mistral-nemo-2407\n",
      "mistral-tiny-2407\n",
      "mistral-tiny-latest\n",
      "open-mixtral-8x7b\n",
      "mistral-small\n",
      "mistral-small-2312\n",
      "open-mixtral-8x22b\n",
      "open-mixtral-8x22b-2404\n",
      "mistral-small-2402\n",
      "mistral-small-2409\n",
      "mistral-medium-2312\n",
      "mistral-large-2402\n",
      "mistral-large-2407\n",
      "mistral-large-2411\n",
      "mistral-large-latest\n",
      "pixtral-large-2411\n",
      "pixtral-large-latest\n",
      "mistral-large-pixtral-2411\n",
      "codestral-2405\n",
      "codestral-2501\n",
      "codestral-latest\n",
      "codestral-2412\n",
      "codestral-2411-rc5\n",
      "devstral-small-2505\n",
      "devstral-small-latest\n",
      "pixtral-12b-2409\n",
      "pixtral-12b\n",
      "pixtral-12b-latest\n",
      "mistral-small-2501\n",
      "mistral-small-2503\n",
      "mistral-small-latest\n",
      "mistral-saba-2502\n",
      "mistral-saba-latest\n",
      "mistral-medium-2505\n",
      "mistral-medium-latest\n",
      "mistral-medium\n",
      "mistral-embed\n",
      "codestral-embed\n",
      "codestral-embed-2505\n",
      "mistral-moderation-2411\n",
      "mistral-moderation-latest\n",
      "mistral-ocr-2503\n",
      "mistral-ocr-2505\n",
      "mistral-ocr-latest\n"
     ]
    }
   ],
   "source": [
    "# model options\n",
    "\n",
    "models = mistral.models.list()\n",
    "for m in models.data:\n",
    "    print(m.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4614ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_with_mistral(text: str, parser, format_instructions: str, label: str) -> BaseModel:\n",
    "\n",
    "    prompt = (\n",
    "    f\"Parse the following text into a structured format according to the provided schema.\"\n",
    "    f\"If the same role at the same company appears more than once, merge the role descriptions and preserve the earliest start and latest end dates.\"\n",
    "    f\"{format_instructions}\\n\\n\"\n",
    "    f\"{label}:\\n{text}\"\n",
    ")\n",
    "\n",
    "    response = mistral.chat.complete(\n",
    "        model=\"mistral-medium-latest\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=2048\n",
    "    )\n",
    "    raw = response.choices[0].message.content\n",
    "    return parser.parse(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9e7d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = df[\"resume_text\"].iloc[6236]\n",
    "parsed_resume = parse_with_mistral(resume_text, resume_parser, resume_parser.get_format_instructions(), \"Resume\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73d61c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": null,\n",
      "  \"location_preference\": null,\n",
      "  \"work_authorizaton\": null,\n",
      "  \"employment_type_preference\": null,\n",
      "  \"hard_skills\": [\n",
      "    \"Microsoft Excel\",\n",
      "    \"Microsoft Outlook\",\n",
      "    \"Adobe Software\",\n",
      "    \"Microsoft Office Suite\",\n",
      "    \"Microsoft Access\",\n",
      "    \"Database Management\",\n",
      "    \"Data Compilation\",\n",
      "    \"Data Review\",\n",
      "    \"Data Verification\"\n",
      "  ],\n",
      "  \"soft_skills\": [\n",
      "    \"Decision Making\",\n",
      "    \"Service-Oriented\",\n",
      "    \"Self-Starter\",\n",
      "    \"Workflow Management\",\n",
      "    \"Attention to Detail\",\n",
      "    \"Multitasking and Prioritization\",\n",
      "    \"Time Management\",\n",
      "    \"Team Player\",\n",
      "    \"Communication\",\n",
      "    \"Leadership\"\n",
      "  ],\n",
      "  \"languages\": [\n",
      "    \"English\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"role\": \"Data Entry Specialist\",\n",
      "      \"company\": \"Sonic Healthcare Usa\",\n",
      "      \"date_start\": \"2020-09-01T00:00:00\",\n",
      "      \"date_end\": \"current\",\n",
      "      \"role_description\": \"Input client information into spreadsheets and company database to provide leaders with quick access to essential client data. Identified, corrected and reported data entry errors. Completed accurate and efficient data entry and database updates to support business operations. Identified and corrected data entry errors to prevent duplication across systems. Compiled data from source documents prior to data entry. Reviewed and updated account information in company computer system. Identified errors in data entry and related issues by mentioning to supervisors for resolution. Sorted source documents and organized to be filed. Adhered to strict data confidentiality policies to prevent information leakage. Communicated with coworkers regarding deadlines and project milestones. Proofread and edited documents to correct errors. Documented data entry completions in corresponding logbooks. Executed data verification to ensure expedient error detection. Exceeded quality goals to support team productivity. Monitored updates to company databases and corrected identified errors. Transferred completed work to Title Officers for review and approval. Reviewed source documents to locate required data for entry. Produced new orders in Streamline Management Services and Greenfolders to manage samples and associated data.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Manager\",\n",
      "      \"company\": \"Community Health System\",\n",
      "      \"date_start\": \"2018-11-01T00:00:00\",\n",
      "      \"date_end\": \"2020-09-01T00:00:00\",\n",
      "      \"role_description\": \"Trained employees on additional job positions to maintain coverage of roles. Assigned tasks to associates to fit skill levels and maximize team performance. Greeted and encouraged feedback from customers to implement in-store operational changes. Completed thorough opening, closing and shift change functions to maintain operational standards each day. Enforced customer service standards and resolved customer problems to uphold quality service. Exercised good judgment and decision-making in escalating concerns and resolving issues. Oversaw daily workloads and workflow for smooth operations. Managed shifts in absence of store manager to deliver excellent customer service while promoting sales.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Crew Member\",\n",
      "      \"company\": \"Marcus Corporation\",\n",
      "      \"date_start\": \"2016-06-01T00:00:00\",\n",
      "      \"date_end\": \"2018-08-01T00:00:00\",\n",
      "      \"role_description\": \"Wiped down tables and equipment, swept and refilled stock. Kept restaurant lobby, front counter and restrooms neat and clean throughout shift. Packed fast food products in approved containers, cups and bags. Entered orders into computer system to send order details to kitchen, mentioning customers' special requests and food allergies in person. Prepared quality products while maintaining portion control and presentation within service goal times. Drove team success by quickly completing assigned tasks. Demonstrated proper food safety practices by accurately completing quality control checklist. Organized and restocked supplies to support operations and team productivity. Served food quickly for positive guest experiences. Packaged menu items into bags or trays and placed drink orders into carriers. Explained current promotional information and items to patrons. Assisted management with inventory control and stock ordering. Presented orders to guests within anticipated service times. Restocked supplies, removed trash and cleaned areas. Answered customer questions and took orders. Prepared products by adding tags and readying pallets for restocking. Operated fryers and grills, assisted with putting orders together and bagged items for customers. Totaled bills, accepted payments and returned change.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Cashier\",\n",
      "      \"company\": \"Kohler\",\n",
      "      \"date_start\": \"2017-06-01T00:00:00\",\n",
      "      \"date_end\": \"2018-04-01T00:00:00\",\n",
      "      \"role_description\": \"Collected payments and provided accurate change. Completed daily recovery tasks to keep areas clean and neat for maximum productivity. Worked closely with front-end staff to assist customers. Accepted cash and credit card payments, issued receipts and provided change. Trained new team members in cash register operation, stock procedures and customer services. Learned roles of other departments to provide coverage and keep store operational. Operated cash register or POS system to receive payment by cash, check and credit card. Reported pricing discrepancies to supervisor. Answered customer questions and provided store information. Delivered high level of customer service to patrons using active listening and engagement skills. Preserved appearance of store by arranging and replenishing displays and merchandise racks.\"\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"High School Diploma\",\n",
      "      \"institution\": \"Idea Homeschool\",\n",
      "      \"date_start\": null,\n",
      "      \"date_end\": null,\n",
      "      \"grade\": null,\n",
      "      \"description\": null\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_resume.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143dea9a",
   "metadata": {},
   "source": [
    "### Parse job desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1b7e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "Hope you are doing great today. Please find the job description below. Let me know your job interest as soon as possible. I will highly appreciate it if you can refer somebody suitable for this position. \n",
      "Role: Data Engineer (Oracle and DataStage).Location: RemoteContract Position\n",
      "Job Description:RoleResponsibilities:Skills: Oracle, Datastage, UNIX, PLSQL, SQL. Good to have: AWS, Matillion, Snowflake. Data engineering experience; expert level experience with SQL. Experience with the cloud (AWS, Azure andor Google Cloud Platform).  Experience in cloud-based data warehouses (Snowflake, Google BigQuery, Amazon Redshift, Azure Synapse Analytics).  Experience with cloud-based ETLELT tools (Matillion, Glue, Data Factory) and data modelling.  Experience with version control systems (Git, SVN).  Understanding of and willingness to embrace Agile Principles. \n",
      "Looking forward to your response . \n",
      "Shubhanshu Tripathishubhanshu.t@cblsolutions.com 469-947-7816 (Ext  209)Cerebral Technologies, Inc (D.B.A CBLSolutions) http:cblsolutions.com400 E Royal Lane, Ste 235, Irving, TX - 75039 Linkedin: https:www.linkedin.cominshubhanshu-tripathi-058228213 \n"
     ]
    }
   ],
   "source": [
    "print(df['job_description_text'].iloc[6236])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "57dd896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_jd = parse_with_mistral(df['job_description_text'].iloc[6236], jd_parser, jd_parser.get_format_instructions(), \"Job Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3fefe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"company_name\": \"Cerebral Technologies, Inc (D.B.A CBLSolutions)\",\n",
      "  \"role_title\": \"Data Engineer (Oracle and DataStage)\",\n",
      "  \"application_deadline\": null,\n",
      "  \"date_posted\": null,\n",
      "  \"employment_type\": \"Contract\",\n",
      "  \"about_the_company\": null,\n",
      "  \"job_responsibilities\": [\n",
      "    \"Data engineering experience\",\n",
      "    \"Expert level experience with SQL\",\n",
      "    \"Experience with the cloud (AWS, Azure, and/or Google Cloud Platform)\",\n",
      "    \"Experience in cloud-based data warehouses (Snowflake, Google BigQuery, Amazon Redshift, Azure Synapse Analytics)\",\n",
      "    \"Experience with cloud-based ETL/ELT tools (Matillion, Glue, Data Factory) and data modeling\",\n",
      "    \"Experience with version control systems (Git, SVN)\",\n",
      "    \"Understanding of and willingness to embrace Agile Principles\"\n",
      "  ],\n",
      "  \"required_hard_skills\": [\n",
      "    \"Oracle\",\n",
      "    \"DataStage\",\n",
      "    \"UNIX\",\n",
      "    \"PLSQL\",\n",
      "    \"SQL\",\n",
      "    \"AWS\",\n",
      "    \"Matillion\",\n",
      "    \"Snowflake\",\n",
      "    \"Google Cloud Platform\",\n",
      "    \"Azure\",\n",
      "    \"Google BigQuery\",\n",
      "    \"Amazon Redshift\",\n",
      "    \"Azure Synapse Analytics\",\n",
      "    \"Glue\",\n",
      "    \"Data Factory\",\n",
      "    \"Git\",\n",
      "    \"SVN\"\n",
      "  ],\n",
      "  \"required_soft_skills\": [\n",
      "    \"Agile Principles\"\n",
      "  ],\n",
      "  \"required_language_proficiencies\": [\n",
      "    \"English\"\n",
      "  ],\n",
      "  \"required_education\": null,\n",
      "  \"required_work_authorization\": null,\n",
      "  \"job_location\": \"Remote\",\n",
      "  \"certifications\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_jd.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53726716-2e47-43d2-9fd6-9018426e5f5b",
   "metadata": {},
   "source": [
    "### Parse Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff99d1a1-6078-4961-9593-8fd3bd1693ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Fit' 'Potential Fit' 'Good Fit']\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9ec25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "No Fit           3143\n",
      "Potential Fit    1556\n",
      "Good Fit         1542\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b71f4",
   "metadata": {},
   "source": [
    "### Parse 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5fbce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_text</th>\n",
       "      <th>job_description_text</th>\n",
       "      <th>label</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>resume_id</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SummaryHighly motivated Sales Associate with e...</td>\n",
       "      <td>Net2Source Inc. is an award-winning total work...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>RES_QDvgj241</td>\n",
       "      <td>JD_QDvgj241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional SummaryCurrently working with Cat...</td>\n",
       "      <td>At Salas OBrien we tell our clients that were ...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-06-09</td>\n",
       "      <td>RES_tvKW28PW</td>\n",
       "      <td>JD_tvKW28PW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SummaryI started my construction career in Jun...</td>\n",
       "      <td>Schweitzer Engineering Laboratories (SEL) Infr...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>RES_Pg6ipOr5</td>\n",
       "      <td>JD_Pg6ipOr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SummaryCertified Electrical Foremanwith thirte...</td>\n",
       "      <td>Mizick Miller &amp; Company, Inc. is looking for a...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>RES_O5bebNRA</td>\n",
       "      <td>JD_O5bebNRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SummaryWith extensive experience in business/r...</td>\n",
       "      <td>Life at Capgemini\\nCapgemini supports all aspe...</td>\n",
       "      <td>No Fit</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>RES_JWSvWYY5</td>\n",
       "      <td>JD_JWSvWYY5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6236</th>\n",
       "      <td>SummaryResults-driven Data Entry Clerk with ex...</td>\n",
       "      <td>Hi,\\nHope you are doing great today. Please fi...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>RES_vNEJ62Py</td>\n",
       "      <td>JD_vNEJ62Py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6237</th>\n",
       "      <td>Professional SummaryWith the attitude of learn...</td>\n",
       "      <td>Job Title: DHT - Front End Software Engineer W...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>RES_DPqh0lVb</td>\n",
       "      <td>JD_DPqh0lVb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6238</th>\n",
       "      <td>Summary•        \\nOver\\nThree years of extensi...</td>\n",
       "      <td>LHH Recruitment Solutions is looking for a Sof...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>RES_1HWrRA5T</td>\n",
       "      <td>JD_1HWrRA5T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>ProfileAbility to prioritize and multi-task in...</td>\n",
       "      <td>Our client is a growing Medical Device company...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>RES_XdUNowSD</td>\n",
       "      <td>JD_XdUNowSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>SummaryFull stack Software Engineer with 8+ ye...</td>\n",
       "      <td>Robert Half is looking for a Senior Full Stack...</td>\n",
       "      <td>Good Fit</td>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>RES_2RPwzELC</td>\n",
       "      <td>JD_2RPwzELC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            resume_text  \\\n",
       "0     SummaryHighly motivated Sales Associate with e...   \n",
       "1     Professional SummaryCurrently working with Cat...   \n",
       "2     SummaryI started my construction career in Jun...   \n",
       "3     SummaryCertified Electrical Foremanwith thirte...   \n",
       "4     SummaryWith extensive experience in business/r...   \n",
       "6236  SummaryResults-driven Data Entry Clerk with ex...   \n",
       "6237  Professional SummaryWith the attitude of learn...   \n",
       "6238  Summary•        \\nOver\\nThree years of extensi...   \n",
       "6239  ProfileAbility to prioritize and multi-task in...   \n",
       "6240  SummaryFull stack Software Engineer with 8+ ye...   \n",
       "\n",
       "                                   job_description_text     label  \\\n",
       "0     Net2Source Inc. is an award-winning total work...    No Fit   \n",
       "1     At Salas OBrien we tell our clients that were ...    No Fit   \n",
       "2     Schweitzer Engineering Laboratories (SEL) Infr...    No Fit   \n",
       "3     Mizick Miller & Company, Inc. is looking for a...    No Fit   \n",
       "4     Life at Capgemini\\nCapgemini supports all aspe...    No Fit   \n",
       "6236  Hi,\\nHope you are doing great today. Please fi...  Good Fit   \n",
       "6237  Job Title: DHT - Front End Software Engineer W...  Good Fit   \n",
       "6238  LHH Recruitment Solutions is looking for a Sof...  Good Fit   \n",
       "6239  Our client is a growing Medical Device company...  Good Fit   \n",
       "6240  Robert Half is looking for a Senior Full Stack...  Good Fit   \n",
       "\n",
       "     snapshot_date     resume_id       job_id  \n",
       "0       2024-10-10  RES_QDvgj241  JD_QDvgj241  \n",
       "1       2024-06-09  RES_tvKW28PW  JD_tvKW28PW  \n",
       "2       2024-11-10  RES_Pg6ipOr5  JD_Pg6ipOr5  \n",
       "3       2024-09-12  RES_O5bebNRA  JD_O5bebNRA  \n",
       "4       2024-02-04  RES_JWSvWYY5  JD_JWSvWYY5  \n",
       "6236    2024-06-02  RES_vNEJ62Py  JD_vNEJ62Py  \n",
       "6237    2024-09-01  RES_DPqh0lVb  JD_DPqh0lVb  \n",
       "6238    2024-11-02  RES_1HWrRA5T  JD_1HWrRA5T  \n",
       "6239    2024-07-26  RES_XdUNowSD  JD_XdUNowSD  \n",
       "6240    2024-08-22  RES_2RPwzELC  JD_2RPwzELC  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = pd.concat([df[:5], df[-5:]])\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b24e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:01<00:00, 18.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(df_subset.iterrows(), total=len(df_subset)):\n",
    "    resume_text = row['resume_text']\n",
    "    jd_text = row['job_description_text']\n",
    "    \n",
    "    try:\n",
    "        # Process resume\n",
    "        parsed_resume = parse_with_mistral(\n",
    "            resume_text,\n",
    "            resume_parser,\n",
    "            resume_parser.get_format_instructions(),\n",
    "            \"Resume\"\n",
    "        )\n",
    "        parsed_resume_dict = parsed_resume.model_dump(mode=\"json\")\n",
    "        resume_output_path = os.path.join('examples_mistral', 'resume', f\"{idx}.json\")\n",
    "        os.makedirs(os.path.dirname(resume_output_path), exist_ok=True) \n",
    "        with open(resume_output_path, \"w\") as f:\n",
    "            json.dump(parsed_resume_dict, f, indent=2)\n",
    "\n",
    "        # Process JD\n",
    "        parsed_jd = parse_with_mistral(\n",
    "            jd_text,\n",
    "            jd_parser,\n",
    "            jd_parser.get_format_instructions(),\n",
    "            \"Job Description\"\n",
    "        )\n",
    "        parsed_jd_dict = parsed_jd.model_dump(mode=\"json\")\n",
    "        jd_output_path = os.path.join('examples_mistral', 'jd', f\"{idx}.json\")\n",
    "        os.makedirs(os.path.dirname(jd_output_path), exist_ok=True) \n",
    "        with open(jd_output_path, \"w\") as f:\n",
    "            json.dump(parsed_jd_dict, f, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing row {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051f325",
   "metadata": {},
   "source": [
    "# Connecting to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9271ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "uri = os.environ.get(\"MONGO_DB_URL\")\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1472c4d3-244d-4412-a25b-300451e8b6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-33636bce-b37b-40ea-a781-b59478f21630;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;10.2.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.8.2 in central\n",
      "\t[4.8.2] org.mongodb#mongodb-driver-sync;[4.8.1,4.8.99)\n",
      "\tfound org.mongodb#bson;4.8.2 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.8.2 in central\n",
      "\tfound org.mongodb#bson-record-codec;4.8.2 in central\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/10.2.0/mongo-spark-connector_2.12-10.2.0.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb.spark#mongo-spark-connector_2.12;10.2.0!mongo-spark-connector_2.12.jar (851ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.8.2/mongodb-driver-sync-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-sync;4.8.2!mongodb-driver-sync.jar (452ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson/4.8.2/bson-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson;4.8.2!bson.jar (858ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.8.2/mongodb-driver-core-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-core;4.8.2!mongodb-driver-core.jar (738ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson-record-codec/4.8.2/bson-record-codec-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson-record-codec;4.8.2!bson-record-codec.jar (371ms)\n",
      ":: resolution report :: resolve 5556ms :: artifacts dl 3283ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.8.2 from central in [default]\n",
      "\torg.mongodb#bson-record-codec;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.8.2 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;10.2.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   5   |   5   |   0   ||   5   |   5   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-33636bce-b37b-40ea-a781-b59478f21630\n",
      "\tconfs: [default]\n",
      "\t5 artifacts copied, 0 already retrieved (2370kB/20ms)\n",
      "25/06/07 06:27:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "mongo_db_url = os.environ.get(\"MONGO_DB_URL\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MongoDBIntegration\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", mongo_db_url) \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", mongo_db_url) \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.2.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac06e8-c7b8-48c1-85d0-12d47269d816",
   "metadata": {},
   "source": [
    "### Save in mongodb per item (incrementing table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client[\"jobmirror_db\"]\n",
    "resume_collection = db[\"resumes\"]\n",
    "jd_collection = db[\"job_descriptions\"]\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    resume_text = row['resume_text']\n",
    "    jd_text = row['job_description_text']\n",
    "    try:\n",
    "        # Process resume\n",
    "        parsed_resume = parse_with_mistral(\n",
    "            resume_text,\n",
    "            resume_parser,\n",
    "            resume_parser.get_format_instructions(),\n",
    "            \"Resume\"\n",
    "        )\n",
    "        parsed_resume_dict = parsed_resume.model_dump(mode=\"json\")\n",
    "        parsed_resume_dict[\"row_idx\"] = idx  \n",
    "        resume_collection.insert_one(parsed_resume_dict) \n",
    "\n",
    "        # Process JD\n",
    "        parsed_jd = parse_with_mistral(\n",
    "            jd_text,\n",
    "            jd_parser,\n",
    "            jd_parser.get_format_instructions(),\n",
    "            \"Job Description\"\n",
    "        )\n",
    "        parsed_jd_dict = parsed_jd.model_dump(mode=\"json\")\n",
    "        parsed_jd_dict[\"row_idx\"] = idx  \n",
    "        jd_collection.insert_one(parsed_jd_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing row {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2db48477-91ec-4fda-bc2a-782b1dd6f05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 640, 'electionId': ObjectId('7fffffff00000000000001b7'), 'opTime': {'ts': Timestamp(1748846844, 37), 't': 439}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1748846844, 37), 'signature': {'hash': b',;\\x0f\\x14\\xdc\\x04\\xae#\\x05\\xf8\\x8d\\xce\\n\\x97y\\xad\\xfd\\xffO\\xa5', 'keyId': 7450535577176244240}}, 'operationTime': Timestamp(1748846844, 37)}, acknowledged=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear collections\n",
    "\n",
    "db = client[\"jobmirror_db\"]\n",
    "resume_collection = db[\"resumes\"]\n",
    "jd_collection = db[\"job_descriptions\"]\n",
    "\n",
    "resume_collection.delete_many({})\n",
    "jd_collection.delete_many({})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180aa45",
   "metadata": {},
   "source": [
    "Convert into PySpark Dataframe (Overwrite table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "396cb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_type_to_spark_type(annotation):\n",
    "    origin = get_origin(annotation)\n",
    "\n",
    "    if origin is Union:  # Handle Optional\n",
    "        args = [arg for arg in get_args(annotation) if arg is not type(None)]\n",
    "        return python_type_to_spark_type(args[0])\n",
    "\n",
    "    if origin in (list, List):\n",
    "        element_type = python_type_to_spark_type(get_args(annotation)[0])\n",
    "        return ArrayType(element_type)\n",
    "\n",
    "    if isinstance(annotation, type):\n",
    "        if issubclass(annotation, BaseModel):\n",
    "            return pydantic_to_spark_schema(annotation)\n",
    "        if issubclass(annotation, str):\n",
    "            return StringType()\n",
    "        if issubclass(annotation, int):\n",
    "            return IntegerType()\n",
    "        if issubclass(annotation, float):\n",
    "            return FloatType()\n",
    "        if issubclass(annotation, bool):\n",
    "            return BooleanType()\n",
    "        if issubclass(annotation, datetime.datetime):\n",
    "            return StringType()\n",
    "\n",
    "    return StringType()\n",
    "\n",
    "def pydantic_to_spark_schema(model: type) -> StructType:\n",
    "    fields = []\n",
    "\n",
    "    for name, field in model.model_fields.items():\n",
    "        annotation = field.annotation\n",
    "\n",
    "        spark_type = python_type_to_spark_type(annotation)\n",
    "        fields.append(StructField(name, spark_type, True))  # assume all nullable\n",
    "    fields.append(StructField('snapshot_date', StringType(), True))\n",
    "    fields.append(StructField('id', StringType(), True))\n",
    "\n",
    "    return StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efbe69-80ca-4f8c-af7d-b5a9c532980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 159/6241 [1:32:54<658:56:45, 390.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing row 158: Server disconnected without sending a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 182/6241 [1:48:55<50:55:45, 30.26s/it]  "
     ]
    }
   ],
   "source": [
    "parsed_resumes = []\n",
    "parsed_jds = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        # Parse resume\n",
    "        parsed_resume = parse_with_mistral(\n",
    "            row['resume_text'],\n",
    "            resume_parser,\n",
    "            resume_parser.get_format_instructions(),\n",
    "            \"Resume\"\n",
    "        )\n",
    "        parsed_resume_dict = parsed_resume.model_dump(mode=\"json\")\n",
    "        parsed_resume_dict['snapshot_date'] = row['snapshot_date']\n",
    "        parsed_resume_dict['id'] = row['resume_id']\n",
    "        parsed_resumes.append(parsed_resume_dict)\n",
    "\n",
    "        # Parse JD\n",
    "        parsed_jd = parse_with_mistral(\n",
    "            row['job_description_text'],\n",
    "            jd_parser,\n",
    "            jd_parser.get_format_instructions(),\n",
    "            \"Job Description\"\n",
    "        )\n",
    "        parsed_jd_dict = parsed_jd.model_dump(mode=\"json\")\n",
    "        parsed_jd_dict['snapshot_date'] = row['snapshot_date']\n",
    "        parsed_jd_dict['id'] = row['job_id']\n",
    "        parsed_jds.append(parsed_jd_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing row {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_schema = pydantic_to_spark_schema(Resume)\n",
    "jd_schema = pydantic_to_spark_schema(JD)\n",
    "\n",
    "resume_df = spark.createDataFrame(parsed_resumes, schema=resume_schema)\n",
    "jd_df = spark.createDataFrame(parsed_jds, schema=jd_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba74bce-b18a-430a-8ad5-437d15cef9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0cd0592e-1b51-4f89-9848-6927a4e5ac12;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;10.5.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;5.1.4 in central\n",
      "\t[5.1.4] org.mongodb#mongodb-driver-sync;[5.1.1,5.1.99)\n",
      "\tfound org.mongodb#bson;5.1.4 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;5.1.4 in central\n",
      "\tfound org.mongodb#bson-record-codec;5.1.4 in central\n",
      ":: resolution report :: resolve 3522ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;5.1.4 from central in [default]\n",
      "\torg.mongodb#bson-record-codec;5.1.4 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;5.1.4 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;5.1.4 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;10.5.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   1   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0cd0592e-1b51-4f89-9848-6927a4e5ac12\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/9ms)\n",
      "25/06/06 14:54:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: string, certifications: array<string>, education: array<struct<degree:string,institution:string,date_start:string,date_end:string,grade:double,description:string,snapshot_date:void,id:void>>, employment_type_preference: string, experience: array<struct<role:string,company:string,date_start:string,date_end:string,role_description:string,snapshot_date:void,id:void>>, hard_skills: array<string>, id: string, languages: array<string>, location_preference: string, name: string, snapshot_date: string, soft_skills: array<string>, work_authorizaton: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_bronze_table_as_pyspark(\"jobmirror_db\", \"bronze_resumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ed169-5470-4b4a-95f9-909a04245ddc",
   "metadata": {},
   "source": [
    "Load data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a62d2e1-6602-4b42-80ee-3d7386a34ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name location_preference work_authorizaton  \\\n",
      "0            None                None              None   \n",
      "1            None                None              None   \n",
      "2  Jessica Claire                None              None   \n",
      "3            None                None              None   \n",
      "4            None                None              None   \n",
      "\n",
      "  employment_type_preference  \\\n",
      "0                       None   \n",
      "1                       None   \n",
      "2                 Internship   \n",
      "3                       None   \n",
      "4                       None   \n",
      "\n",
      "                                         hard_skills  \\\n",
      "0  [React, Javascript, GraphQL, JSON, MySQL, JIRA...   \n",
      "1  [C, C++, Java, VHDL, Shell, Python, Perl, MATL...   \n",
      "2  [ATM, C++, CCNA, Cisco, DSL, Ethernet, LAN, Li...   \n",
      "3  [Accounting, Tax Accounting, Account Reconcili...   \n",
      "4  [QuickBooks, Word, Excel, Epic, CPN, Data coll...   \n",
      "\n",
      "                                         soft_skills  languages  \\\n",
      "0  [Design and development, UI/UX, Testing and de...  [English]   \n",
      "1              [teamwork, leadership, communication]  [English]   \n",
      "2  [clients, procurement, progress, Supervising, ...  [English]   \n",
      "3  [Strong Organizational Skills, Effective Time ...  [English]   \n",
      "4  [Organizational skills, Active listening, Prob...  [English]   \n",
      "\n",
      "                                          experience  \\\n",
      "0  [{'role': 'Software Engineer Front End', 'comp...   \n",
      "1  [{'role': 'Embedded Software Engineer', 'compa...   \n",
      "2  [{'role': 'Electrical & Instrumentation Engine...   \n",
      "3  [{'role': 'Accountant II', 'company': 'Graphic...   \n",
      "4  [{'role': 'Secretary/Customer Service/Sales/Da...   \n",
      "\n",
      "                                           education  \\\n",
      "0  [{'degree': 'Bachelor of Science', 'institutio...   \n",
      "1  [{'degree': 'Bachelor of Engineering', 'instit...   \n",
      "2  [{'degree': 'Master of Science', 'institution'...   \n",
      "3  [{'degree': 'Master of Science: Accounting', '...   \n",
      "4  [{'degree': 'Cosmetology License', 'institutio...   \n",
      "\n",
      "                                      certifications snapshot_date  \\\n",
      "0                                                 []    2021-10-30   \n",
      "1                                                 []    2021-09-17   \n",
      "2  [ADCO PTW (Permit To-Work) system training cer...    2021-07-15   \n",
      "3                                                 []    2021-10-15   \n",
      "4                 [Cosmetology License, CNA License]    2021-06-16   \n",
      "\n",
      "             id  \n",
      "0  RES_Lrgk1qIc  \n",
      "1  RES_kUoPlNoI  \n",
      "2  RES_s93wTCLp  \n",
      "3  RES_W35SEzlG  \n",
      "4  RES_kQiZZseA  \n"
     ]
    }
   ],
   "source": [
    "df_bronze_resume = read_bronze_table_as_pandas(\"jobmirror_db\", \"bronze_resumes\")\n",
    "print(df_bronze_resume.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d373afdf-2cd1-4845-a6e1-9dfd21123a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4229 entries, 0 to 4228\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   name                        148 non-null    object\n",
      " 1   location_preference         105 non-null    object\n",
      " 2   work_authorizaton           99 non-null     object\n",
      " 3   employment_type_preference  224 non-null    object\n",
      " 4   hard_skills                 4229 non-null   object\n",
      " 5   soft_skills                 4229 non-null   object\n",
      " 6   languages                   4229 non-null   object\n",
      " 7   experience                  4229 non-null   object\n",
      " 8   education                   4229 non-null   object\n",
      " 9   certifications              4229 non-null   object\n",
      " 10  snapshot_date               4229 non-null   object\n",
      " 11  id                          4229 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 396.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bronze_resume.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd629d2-53d1-4f68-8090-d59e5aa99584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             company_name                          role_title  \\\n",
      "0  Medical Device Company  Senior Digital Electronic Engineer   \n",
      "1                  Fiserv        Software Engineering Manager   \n",
      "2                    None                 Electronic Engineer   \n",
      "3                  Dexian                  Accounting Manager   \n",
      "4              BNY Mellon                Business Analyst III   \n",
      "\n",
      "  application_deadline date_posted employment_type  \\\n",
      "0                 None        None       Full-time   \n",
      "1                 None        None       Full-time   \n",
      "2                 None        None       Full-time   \n",
      "3                 None        None       Full-time   \n",
      "4                 None        None        Contract   \n",
      "\n",
      "                                   about_the_company  \\\n",
      "0  A growing Medical Device company located in Pa...   \n",
      "1  Fiserv is a global leader in Fintech and payme...   \n",
      "2  An acoustics, weapon launch and control system...   \n",
      "3  Dexian, formerly Hunter Hollis, is working wit...   \n",
      "4  Enterprises Data Governance Under Data Quality...   \n",
      "\n",
      "                                job_responsibilities  \\\n",
      "0  [Design and develop digital circuits and schem...   \n",
      "1  [Manage cross-functional engineering teams, Ha...   \n",
      "2  [Analyze and design analog and digital electro...   \n",
      "3  [Manage the revenue recognition process accord...   \n",
      "4  [Working with Data Quality rules and Data Lake...   \n",
      "\n",
      "                                required_hard_skills  \\\n",
      "0  [Digital Circuit Design, Schematics, Microproc...   \n",
      "1  [C, Java, Software Engineering, Financial Serv...   \n",
      "2  [Analog and digital electronic circuit design,...   \n",
      "3  [Revenue cycle management, Accounts receivable...   \n",
      "4  [Data Quality Model, SQL, Collibra, Jira, Conf...   \n",
      "\n",
      "                                required_soft_skills  \\\n",
      "0           [Teamwork, Communication, Documentation]   \n",
      "1  [Communication, Leadership, Problem Solving, T...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4     [Working with Matrix, Data Analysis, Teamwork]   \n",
      "\n",
      "  required_language_proficiencies  \\\n",
      "0                       [English]   \n",
      "1                       [English]   \n",
      "2                       [English]   \n",
      "3                       [English]   \n",
      "4                       [English]   \n",
      "\n",
      "                                  required_education  \\\n",
      "0  Bachelor's degree in Electrical or Electronics...   \n",
      "1  Bachelor's degree in computer science, enginee...   \n",
      "2                                               None   \n",
      "3                                  Bachelor's Degree   \n",
      "4  Minimum 8-12 years of working experience in th...   \n",
      "\n",
      "                         required_work_authorization  \\\n",
      "0                                               None   \n",
      "1                                               None   \n",
      "2  US Citizen, Active Secret (Will Sponsor a Secr...   \n",
      "3                                               None   \n",
      "4            Candidates without any Visa Constraints   \n",
      "\n",
      "                                   job_location     certifications  \\\n",
      "0         Parsippany, NJ (Onsite 5 days a week)                 []   \n",
      "1                                          None  [AWS, Azure, GCP]   \n",
      "2                         Manassas, VA (Hybrid)                 []   \n",
      "3                              Durham, RTP area                 []   \n",
      "4  Pittsburgh, PA (Hybrid model, 3 days a week)                 []   \n",
      "\n",
      "  snapshot_date           id  \n",
      "0    2021-10-30  JD_Lrgk1qIc  \n",
      "1    2021-09-17  JD_kUoPlNoI  \n",
      "2    2021-07-15  JD_s93wTCLp  \n",
      "3    2021-10-15  JD_W35SEzlG  \n",
      "4    2021-06-16  JD_kQiZZseA  \n"
     ]
    }
   ],
   "source": [
    "df_bronze_jd = read_bronze_table_as_pandas(\"jobmirror_db\", \"bronze_job_descriptions\")\n",
    "print(df_bronze_jd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "666f9b40-f0f3-4dc7-bb43-40b23603db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 16 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   company_name                     2625 non-null   object\n",
      " 1   role_title                       4050 non-null   object\n",
      " 2   application_deadline             0 non-null      object\n",
      " 3   date_posted                      43 non-null     object\n",
      " 4   employment_type                  4144 non-null   object\n",
      " 5   about_the_company                2493 non-null   object\n",
      " 6   job_responsibilities             4177 non-null   object\n",
      " 7   required_hard_skills             4177 non-null   object\n",
      " 8   required_soft_skills             4177 non-null   object\n",
      " 9   required_language_proficiencies  4177 non-null   object\n",
      " 10  required_education               2880 non-null   object\n",
      " 11  required_work_authorization      794 non-null    object\n",
      " 12  job_location                     2738 non-null   object\n",
      " 13  certifications                   4177 non-null   object\n",
      " 14  snapshot_date                    4177 non-null   object\n",
      " 15  id                               4177 non-null   object\n",
      "dtypes: object(16)\n",
      "memory usage: 522.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bronze_jd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76debaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label_id     resume_id       job_id     fit snapshot_date\n",
      "0  LABEL_Lrgk1qIc  RES_Lrgk1qIc  JD_Lrgk1qIc  No Fit    2021-10-30\n",
      "1  LABEL_kUoPlNoI  RES_kUoPlNoI  JD_kUoPlNoI  No Fit    2021-09-17\n",
      "2  LABEL_s93wTCLp  RES_s93wTCLp  JD_s93wTCLp  No Fit    2021-07-15\n",
      "3  LABEL_W35SEzlG  RES_W35SEzlG  JD_W35SEzlG  No Fit    2021-10-15\n",
      "4  LABEL_kQiZZseA  RES_kQiZZseA  JD_kQiZZseA  No Fit    2021-06-16\n"
     ]
    }
   ],
   "source": [
    "df_label= read_bronze_table_as_pandas(\"jobmirror_db\", \"bronze_labels\")\n",
    "print(df_label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47867a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 997 entries, 0 to 996\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   label_id       997 non-null    object\n",
      " 1   resume_id      997 non-null    object\n",
      " 2   job_id         997 non-null    object\n",
      " 3   fit            997 non-null    object\n",
      " 4   snapshot_date  997 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 39.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_label.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f185d77",
   "metadata": {},
   "source": [
    "# SILVER\n",
    "\n",
    "1. Check data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a8a66",
   "metadata": {},
   "source": [
    "# GOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5416e",
   "metadata": {},
   "source": [
    "## Get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52d6567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f948ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_required_skills = embedding_model.embed_documents(parsed_jd.required_hard_skills)\n",
    "embeddings_skills_owned = embedding_model.embed_documents(parsed_resume.hard_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93af6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_skills = np.array(embeddings_required_skills)\n",
    "skills_owned = np.array(embeddings_skills_owned)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "required_skills = required_skills / np.linalg.norm(required_skills, axis=1, keepdims=True)\n",
    "skills_owned = skills_owned / np.linalg.norm(skills_owned, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(required_skills, skills_owned.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ae5fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required: PostgreSQL  <=> Best Owned: PostgreSQL  | Similarity: 1.00\n",
      "Required: Express  <=> Best Owned: EF  | Similarity: 0.63\n",
      "Required: React  <=> Best Owned: HTML5  | Similarity: 0.63\n",
      "Required: NodeJS  <=> Best Owned: AngularJS  | Similarity: 0.73\n",
      "Required: Redux  <=> Best Owned: Redmine  | Similarity: 0.63\n",
      "Required: HTML  <=> Best Owned: HTML  | Similarity: 1.00\n",
      "Required: CSS  <=> Best Owned: CSS  | Similarity: 1.00\n",
      "Required: JavaScript  <=> Best Owned: jQuery  | Similarity: 0.86\n",
      "Required: JSON  <=> Best Owned: JSON  | Similarity: 1.00\n",
      "Required: Git  <=> Best Owned: GIT  | Similarity: 0.95\n",
      "Required: REST  <=> Best Owned: REST  | Similarity: 1.00\n",
      "Required: Firebase  <=> Best Owned: Hangfire  | Similarity: 0.62\n",
      "Required: Material-UI  <=> Best Owned: AngularJS  | Similarity: 0.63\n",
      "Required: D3js  <=> Best Owned: jQuery  | Similarity: 0.72\n",
      "Required: Docker (Compose)  <=> Best Owned: Composer  | Similarity: 0.67\n",
      "Required: AWS  <=> Best Owned: AWS EC2  | Similarity: 0.85\n"
     ]
    }
   ],
   "source": [
    "best_matches = []\n",
    "\n",
    "for i, req_skill in enumerate(parsed_jd.required_hard_skills):\n",
    "    j = similarity_matrix[i].argmax()\n",
    "    score = similarity_matrix[i, j]\n",
    "    if score >= 0.6:\n",
    "        best_matches.append((req_skill, parsed_resume.hard_skills[j], score))\n",
    "\n",
    "# Print\n",
    "for req_skill, own_skill, score in best_matches:\n",
    "    print(f\"Required: {req_skill}  <=> Best Owned: {own_skill}  | Similarity: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "991dbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_role_name = embedding_model.embed_query(parsed_jd.role_title)\n",
    "embeddings_experience_titles = embedding_model.embed_documents([exp.role for exp in parsed_resume.experience])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65b9e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Full Stack Engineer (PERN Stack)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_jd.role_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4e5d683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Software Developer',\n",
       " 'Software .Net Developer',\n",
       " 'Software Engineer and Professor']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[exp.role for exp in parsed_resume.experience]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31d693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = np.array(embeddings_role_name)\n",
    "experiences = np.array(embeddings_experience_titles)\n",
    "\n",
    "# Normalize embeddings to unit vectors (L2 norm)\n",
    "role_name = role_name / np.linalg.norm(role_name)\n",
    "experiences = experiences / np.linalg.norm(experiences, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix by dot product\n",
    "similarity_matrix = np.dot(experiences, role_name.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5a979df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65028087, 0.62905722, 0.6121288 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
